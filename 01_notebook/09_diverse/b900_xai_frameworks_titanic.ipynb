{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true,"collapsed_sections":["9KvrJJ9IsMmL","hmnsVlyfsYnM","h1Y4Mz_5s0j4","Y1dy1rsJtdoL","NP5vkLi_tnyh","gPKXqPv0uh46","gSln2Aspu5cx","1JvexF9ywXvL","I1AHXekjzbJx","Pza94X-Wzihv","YPVjViE14yeA","VwPl5iaW5SZm","YOurdh5T55kA"],"authorship_tag":"ABX9TyON557qZlkPKyWJJnMh4Qko"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Machine Learning\n","</b></font> </br></p>\n","<p><font size=\"5\" color='grey'> <b>\n","XAI Frameworks im Vergleich - Titanic\n","</b></font> </br></p>\n","\n","---"],"metadata":{"id":"10MSJC42rQuE"}},{"cell_type":"markdown","source":["**Explainable AI (XAI) Frameworks:**\n","\n","- üîç **LIME** - Local Interpretable Model-agnostic Explanations\n","- üéØ **SHAP** - SHapley Additive exPlanations  \n","- üë∂ **ELI5** - Explain Like I'm 5\n","- üè¢ **InterpretML** - Microsoft's umfassendes Framework\n","\n","Dieses Notebook vergleicht alle wichtigen XAI-Frameworks am Titanic-Datensatz.\n","\n","---\n","\n","**üìö Wichtige Begriffe f√ºr dieses Notebook:**\n","\n","| Begriff | Bedeutung |\n","|---------|----------|\n","| **Black-Box-Modell** | ML-Modell, dessen Entscheidungslogik nicht direkt einsehbar ist (z.B. Random Forest, neuronale Netze) |\n","| **Modell-agnostisch** | Die Methode funktioniert bei jedem Modelltyp ‚Äì egal ob Random Forest, XGBoost oder neuronales Netz |\n","| **Lokal vs. Global** | Lokal = erkl√§rt eine einzelne Vorhersage; Global = erkl√§rt das gesamte Modellverhalten |\n","| **Feature Importance** | Wie wichtig ist ein Merkmal f√ºr die Vorhersage? |\n","| **Perturbation** | Gezieltes Ver√§ndern von Eingabewerten, um deren Einfluss zu messen |\n"],"metadata":{"id":"479Z1zQ7ryDT"}},{"cell_type":"markdown","source":["# 0  | Install & Import\n","---"],"metadata":{"id":"9KvrJJ9IsMmL"}},{"cell_type":"code","source":["# Install - Verwendet normales pip (funktioniert in allen Umgebungen)\n","!uv pip install -q shap lime eli5 interpret plotly\n","!uv pip install -q git+https://github.com/parrt/dtreeviz.git\n","\n","print(\"‚úÖ Alle Pakete installiert\")"],"metadata":{"id":"lJycSr3Qr52r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import\n","from pandas import read_excel, DataFrame\n","import numpy as np\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# XAI Frameworks\n","import shap\n","import lime\n","from lime.lime_tabular import LimeTabularExplainer\n","import eli5\n","from eli5.sklearn import PermutationImportance\n","from interpret import show\n","from interpret.blackbox import ShapKernel\n","\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","import dtreeviz"],"metadata":{"id":"KXTXGi-asBgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Warnung ausstellen\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Matplotlib-spezifische Warnungen unterdr√ºcken\n","import logging\n","logging.getLogger('matplotlib').setLevel(logging.ERROR)"],"metadata":{"id":"W_2wjS1DsU1z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1  | Understand\n","---"],"metadata":{"id":"hmnsVlyfsYnM"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üìí Anwendungsfall\n","</font></p>"],"metadata":{"id":"24p7rhtbsdGw"}},{"cell_type":"markdown","source":["Der legend√§re Titanic ML-Wettbewerb: Vorhersage, welche Passagiere √ºberlebt haben.\n","\n","**Ziel**: Vergleich verschiedener XAI-Frameworks zur Erkl√§rung der Modellvorhersagen.\n","\n","**Beispielpersonen:**\n","- üë∞ **Rose DeWitt Bukater** (Kate Winslet) - 1. Klasse, weiblich, 22 Jahre\n","- üé® **Jack Dawson** (Leonardo DiCaprio) - 3. Klasse, m√§nnlich, 23 Jahre\n"],"metadata":{"id":"jLZRJse9sqVQ"}},{"cell_type":"code","source":["df = read_excel(\n","    \"https://raw.githubusercontent.com/ralf-42/ML_Intro/main/02_daten/05_tabellen/titanic.xlsx\",\n","    usecols=[\"pclass\", \"survived\", \"sex\", \"age\", \"sibsp\", \"parch\"],\n",")\n","\n","data = df.copy()\n","target = data.pop(\"survived\")\n","\n","data.head()"],"metadata":{"id":"O9sBORJ4swBf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  2 | Prepare\n","---\n"],"metadata":{"id":"h1Y4Mz_5s0j4"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">üìã Checkliste</font></p>\n","\n","‚úÖ Train-Test-Split durchf√ºhren</br>\n","‚úÖ Nicht ben√∂tigte Features l√∂schen</br>\n","‚úÖ Datentyp ermitteln/√§ndern</br>\n","‚úÖ Missing Values behandeln</br>\n","‚úÖ Ausrei√üer behandeln</br>\n","‚úÖ Kategorischer Features Kodieren</br>\n","‚úÖ Numerischer Features skalieren</br>\n","‚úÖ Feature-Engineering (neue Features schaffen)</br>\n","‚úÖ Dimensionalit√§t reduzieren</br>\n","‚úÖ Resampling (Over-/Undersampling)</br>\n","‚úÖ Pipeline erstellen/konfigurieren</br>\n"],"metadata":{"id":"RJy82YNPs4Zv"}},{"cell_type":"markdown","source":["<font color='black' size=\"5\">\n","Datentyp ermitteln\n","</font>\n"],"metadata":{"id":"rLF76GZls9vd"}},{"cell_type":"code","source":["all_col = data.columns\n","num_col = data.select_dtypes(include=\"number\").columns\n","cat_col = data.select_dtypes(exclude=\"number\").columns"],"metadata":{"id":"RB3RD5SAtDwe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='black' size=\"5\">\n","Train-Test-Set\n","</font>\n"],"metadata":{"id":"RCjPAG2etG2j"}},{"cell_type":"code","source":["data_train, data_test, target_train, target_test = train_test_split(\n","    data, target, test_size=0.20, stratify=target, random_state=42)"],"metadata":{"id":"5O8XwlrEtJvE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='black' size=\"5\">\n","Missing Values behandeln\n","</font>"],"metadata":{"id":"lsNFuK30tMp9"}},{"cell_type":"code","source":["# Missing Values - numerische Features (z.B. age)\n","imputer_num = SimpleImputer(strategy=\"mean\")\n","imputer_num.fit(data_train[num_col])\n","data_train[num_col] = imputer_num.transform(data_train[num_col])\n","data_test[num_col] = imputer_num.transform(data_test[num_col])\n","\n","# Missing Values - kategoriale Features (z.B. sex)\n","imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n","imputer_cat.fit(data_train[cat_col])\n","data_train[cat_col] = imputer_cat.transform(data_train[cat_col])\n","data_test[cat_col] = imputer_cat.transform(data_test[cat_col])"],"metadata":{"id":"yq2n4G3ftQrq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='black' size=\"5\">\n","Kodierung\n","</font>"],"metadata":{"id":"k3r77-POtWSb"}},{"cell_type":"code","source":["encoder = OrdinalEncoder()\n","encoder.fit(data_train[cat_col])\n","data_train[cat_col] = encoder.transform(data_train[cat_col])\n","data_test[cat_col] = encoder.transform(data_test[cat_col])"],"metadata":{"id":"-IjyRQO4taSG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 | Modeling\n","---"],"metadata":{"id":"Y1dy1rsJtdoL"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üèÉ Modellauswahl & Training\n","</font></p>\n"],"metadata":{"id":"vwAGVzfOtggF"}},{"cell_type":"code","source":["# RandomForestClassifier mit optimierten Hyperparametern (ohne Pipeline!)\n","# Reduziert Overfitting durch:\n","# - Mehr B√§ume (n_estimators=200)\n","# - Weniger tiefe B√§ume (max_depth=5)\n","# - Gr√∂√üere Mindestanzahl pro Blatt (min_samples_leaf=5)\n","# - Gr√∂√üere Mindestanzahl f√ºr Split (min_samples_split=10)\n","\n","model = RandomForestClassifier(\n","    n_estimators=200,        # Mehr B√§ume f√ºr stabilere Vorhersagen\n","    max_depth=5,             # Weniger tief = weniger Overfitting\n","    min_samples_split=10,    # Mind. 10 Samples f√ºr Split\n","    min_samples_leaf=5,      # Mind. 5 Samples pro Blatt\n","    max_features='sqrt',     # Nur Wurzel der Features pro Split\n","    random_state=42\n",")\n","\n","model.fit(data_train, target_train)"],"metadata":{"id":"Ox-H3kV9tklS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4 | Evaluate\n","---"],"metadata":{"id":"NP5vkLi_tnyh"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üéØ Accuracy\n","</font></p>\n"],"metadata":{"id":"8eacP_ZOtrge"}},{"cell_type":"code","source":["target_train_pred = model.predict(data_train)\n","target_test_pred = model.predict(data_test)\n","\n","acc_train = accuracy_score(target_train, target_train_pred) * 100\n","acc_test = accuracy_score(target_test, target_test_pred) * 100\n","\n","print(f\"Train Accuracy: {acc_train:5.2f}%\")\n","print(f\"Test Accuracy:  {acc_test:5.2f}%\")"],"metadata":{"id":"vWJmOgcStunR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üìù Testpersonen: Rose & Jack\n","</font></p>"],"metadata":{"id":"OScYOG7-txsB"}},{"cell_type":"code","source":["# Rose DeWitt Bukater (Kate Winslet) - Original-Werte (keine Skalierung!)\n","rose = DataFrame(\n","    {\"age\": [22], \"sex\": [0], \"sibsp\": [0], \"parch\": [1], \"pclass\": [1]},  # sex=1 (female)\n","    index=[\"Rose\"],\n",")\n","\n","# Jack Dawson (Leonardo DiCaprio) - Original-Werte (keine Skalierung!)\n","jack = DataFrame(\n","    {\"age\": [23], \"sex\": [1], \"sibsp\": [0], \"parch\": [0], \"pclass\": [3]},  # sex=0 (male)\n","    index=[\"Jack\"],\n",")\n","\n","rose_pred = model.predict_proba(rose)[0][1] * 100\n","jack_pred = model.predict_proba(jack)[0][1] * 100\n","\n","print(f\"üë∞ Rose √úberlebenschance: {rose_pred:.2f}%\")\n","print(f\"   (22 Jahre, weiblich, 1. Klasse)\")\n","print(f\"üé® Jack √úberlebenschance: {jack_pred:.2f}%\")\n","print(f\"   (23 Jahre, m√§nnlich, 3. Klasse)\")"],"metadata":{"id":"w-aoqbkKt4ZN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üå≥ Entscheidungsbaum Visualisierung\n","</font></p>\n","\n","**Hinweis**: RandomForest besteht aus 200 B√§umen. Hier wird nur der ersten Baum als Beispiel visualisiert.\n"],"metadata":{"id":"XvnTS-trt7kQ"}},{"cell_type":"code","source":["# Extrahiere den ersten Baum aus dem RandomForest\n","single_tree = model.estimators_[1]\n","\n","# Erstelle dtreeviz Visualisierung f√ºr diesen einzelnen Baum\n","viz_model = dtreeviz.model(\n","    single_tree,\n","    X_train=data_train,\n","    y_train=target_train,\n","    target_name=\"survived\",\n","    class_names=[\"not survived\", \"survived\"],\n","    feature_names=list(data_train.columns),\n",")\n","\n","print(f\"‚úÖ Visualisierung f√ºr Baum 1 von {model.n_estimators} erstellt\")"],"metadata":{"id":"nLk5nzYmuAil"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualisierung f√ºr diesen einzelnen Baum\n","viz_model.view(scale=1.0, fontname=\"Monospace\")"],"metadata":{"id":"f-LidxUvuHKG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Local Explanation f√ºr Rose - total\n","one = rose.iloc[0].values\n","viz_model.view(x=one, scale=1.0, fontname=\"Monospace\")"],"metadata":{"id":"yPZbkA4DuSSd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# local Explanation - single\n","viz_model.view(x=one, scale=1.2, show_just_path=True, fontname=\"Monospace\")"],"metadata":{"id":"NrTBzjFhu0ZO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5 | Deploy\n","---"],"metadata":{"id":"gPKXqPv0uh46"}},{"cell_type":"markdown","source":["# A | XAI mit LIME üîç\n","---"],"metadata":{"id":"gSln2Aspu5cx"}},{"cell_type":"markdown","source":["**LIME** = Local Interpretable Model-agnostic Explanations"],"metadata":{"id":"jEN_liK5u-tx"}},{"cell_type":"markdown","source":["**Was macht LIME?**\n","\n","LIME erkl√§rt **einzelne Vorhersagen**, indem es ein einfaches, verst√§ndliches Modell lokal um den zu erkl√§renden Datenpunkt herum trainiert.\n","\n","**Wie funktioniert LIME?**\n","\n","1. **Perturbation**: LIME erzeugt viele leicht ver√§nderte Versionen des Datenpunkts (z.B. Alter ¬±5 Jahre, andere Klasse)\n","2. **Vorhersagen sammeln**: Das Black-Box-Modell bewertet alle perturbierten Samples\n","3. **Gewichtung**: Samples, die dem Original √§hnlicher sind, bekommen mehr Gewicht\n","4. **Lokales Modell**: Ein einfaches lineares Modell wird auf diese gewichteten Samples trainiert\n","5. **Interpretation**: Die Koeffizienten des linearen Modells zeigen den Einfluss jedes Features\n","\n","**Warum \"lokal\"**?\n","\n","LIME erkl√§rt nicht das gesamte Modell, sondern nur die **unmittelbare Umgebung** eines Datenpunkts. Die Erkl√§rung f√ºr Rose kann v√∂llig anders aussehen als die f√ºr Jack.\n","\n","**Vorteile**\n","- ‚úÖ Funktioniert mit **jedem** Modell (modell-agnostisch)\n","- ‚úÖ Sehr **intuitiv** zu verstehen\n","- ‚úÖ **Schnell** f√ºr einzelne Vorhersagen\n"],"metadata":{"id":"aYFyhkDXvOda"}},{"cell_type":"code","source":["# LIME Explainer mit vorverarbeiteten Daten erstellen\n","lime_explainer = LimeTabularExplainer(\n","    data_train.values,\n","    feature_names=data_train.columns.tolist(),\n","    class_names=['Not Survived', 'Survived'],\n","    categorical_features=[data_train.columns.get_loc('sex'), data_train.columns.get_loc('pclass')],\n","    mode='classification'\n",")\n","\n","print(\"‚úÖ LIME Explainer erstellt\")\n","print(\"   Features:\", data_train.columns.tolist())"],"metadata":{"id":"ZcvBv7MdvG4Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üë∞ Rose mit LIME erkl√§ren\n","</font></p>\n"],"metadata":{"id":"eqd2eoNpvKEu"}},{"cell_type":"code","source":["# Rose mit LIME erkl√§ren\n","rose_lime_exp = lime_explainer.explain_instance(\n","    rose.iloc[0].values,\n","    model.predict_proba,\n","    num_features=5\n",")\n","rose_lime_exp.show_in_notebook(show_table=True)"],"metadata":{"id":"gpWzUUlLvRzw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üé® Jack mit LIME erkl√§ren\n","</font></p>"],"metadata":{"id":"K2oP8h0iva5r"}},{"cell_type":"code","source":["# Jack mit LIME erkl√§ren\n","jack_lime_exp = lime_explainer.explain_instance(\n","    jack.iloc[0].values,\n","    model.predict_proba,\n","    num_features=5\n",")\n","\n","jack_lime_exp.show_in_notebook(show_table=True)"],"metadata":{"id":"1-5vMprOv_wR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='blue' size=\"4\">\n","üí° LIME Interpretation\n","</font></p>"],"metadata":{"id":"b4btij2iwIKX"}},{"cell_type":"markdown","source":["**Balkendiagramm:**\n","- **Orange Balken**: Erh√∂hen die √úberlebenschance (Klasse \"Survived\")\n","- **Blaue Balken**: Verringern die √úberlebenschance (Klasse \"Not Survived\")\n","- **Werte**: Wie stark beeinflusst das Feature die Vorhersage\n","\n","**PrScore (Prediction Score) Tabelle:**\n","- Zeigt die Vorhersage-Wahrscheinlichkeit f√ºr **beide Klassen**\n","- **Not Survived**: Wahrscheinlichkeit f√ºr Tod (h√∂her bei Jack)\n","- **Survived**: Wahrscheinlichkeit f√ºr √úberleben (h√∂her bei Rose)\n","- Beide Werte zusammen ergeben immer 100%\n","\n","**Beispiel:**\n","- Rose: Not Survived ‚âà 38%, **Survived ‚âà 62%**\n","- Jack: **Not Survived ‚âà 93%**, Survived ‚âà 7%\n","\n","‚ö†Ô∏è **Wichtig**: Der PrScore f√ºr \"Not Survived\" ist bei Jack h√∂her - das bedeutet er hat eine h√∂here Todeswahrscheinlichkeit, nicht eine h√∂here √úberlebenschance!\n","\n","**Erkenntnisse:**\n","- Rose: `sex=0` (female) und `pclass=1` erh√∂hen massiv die √úberlebenschance\n","- Jack: `sex=1` (male) und `pclass=3` verringern massiv die √úberlebenschance\n"],"metadata":{"id":"Vzix_xDiwSpl"}},{"cell_type":"markdown","source":["# B | XAI mit SHAP üéØ\n","---"],"metadata":{"id":"1JvexF9ywXvL"}},{"cell_type":"markdown","source":["**SHAP** = SHapley Additive exPlanations"],"metadata":{"id":"PaZ5mYXAy3HD"}},{"cell_type":"markdown","source":["**Was macht SHAP?**\n","\n","SHAP berechnet den **Beitrag jedes Features** zur Vorhersage, basierend auf einem mathematisch fundierten Konzept aus der Spieltheorie.\n","\n","**Die Spieltheorie-Idee (vereinfacht**)\n","\n","Stellen Sie sich ein Team von Spielern vor, das gemeinsam einen Preis gewinnt. Wie verteilt man den Gewinn **fair**? Die Shapley-Werte l√∂sen genau dieses Problem.\n","\n","**√úbertragen auf ML:**\n","- **Spieler** = Features (Alter, Geschlecht, Klasse, ...)\n","- **Gewinn** = Vorhersage des Modells\n","- **Frage**: Wie viel tr√§gt jedes Feature zur Vorhersage bei?\n","\n","**Wie funktioniert SHAP**?\n","\n","1. Betrachte **alle m√∂glichen Kombinationen** von Features\n","2. Berechne f√ºr jede Kombination: Was √§ndert sich, wenn ich Feature X hinzuf√ºge?\n","3. Der **Durchschnitt** √ºber alle Kombinationen = SHAP-Wert des Features\n","\n","**Interpretation der SHAP-Werte**\n","\n","| SHAP-Wert | Bedeutung |\n","|-----------|----------|\n","| **Positiv (+)** | Feature erh√∂ht die Vorhersage (hier: √úberlebenschance) |\n","| **Negativ (-)** | Feature senkt die Vorhersage |\n","| **Nahe 0** | Feature hat wenig Einfluss auf diese Vorhersage |\n","\n","**Vorteile gegen√ºber LIME**\n","- ‚úÖ **Theoretisch fundiert** ‚Äì mathematisch beweisbar fair\n","- ‚úÖ Funktioniert **lokal und global**\n","- ‚úÖ Die Summe aller SHAP-Werte ergibt die Vorhersage\n"],"metadata":{"id":"vQnhGgig0ex8"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","‚öôÔ∏è SHAP Explainer erstellen\n","</font></p>"],"metadata":{"id":"lc23VB6Zy77b"}},{"cell_type":"code","source":["# SHAP TreeExplainer (optimal f√ºr RandomForest - sehr schnell!)\n","shap_explainer = shap.TreeExplainer(model)\n","\n","print(\"‚úÖ SHAP TreeExplainer erstellt (optimiert f√ºr RandomForest)\")"],"metadata":{"id":"latKvvfUy_w2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üë∞ Rose mit SHAP erkl√§ren (Waterfall Plot)\n","</font></p>\n"],"metadata":{"id":"Behk93PPzEDD"}},{"cell_type":"code","source":["rose_shap = shap_explainer(rose)\n","\n","# Waterfall Plot f√ºr Klasse \"Survived\" (Index 1)\n","shap.plots.waterfall(rose_shap[0, :, 1])"],"metadata":{"id":"K1_pUy--zIGD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üé® Jack mit SHAP erkl√§ren (Waterfall Plot)\n","</font></p>"],"metadata":{"id":"AdzjIlEhzLsL"}},{"cell_type":"code","source":["jack_shap = shap_explainer(jack)\n","\n","# Waterfall Plot f√ºr Klasse \"Survived\" (Index 1)\n","shap.plots.waterfall(jack_shap[0, :, 1])"],"metadata":{"id":"SVmR4h-Pz0VY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='blue' size=\"4\">\n","üí° SHAP Interpretation\n","</font></p>\n","\n","**Waterfall Plot:**\n","- Zeigt, wie sich die Vorhersage vom Durchschnittswert (E[f(x)]) zum finalen Wert aufbaut\n","- Jeder Pfeil = Beitrag eines Features\n","- Rot = erh√∂ht die √úberlebenschance, Blau = verringert sie"],"metadata":{"id":"Ovzylx300EGz"}},{"cell_type":"markdown","source":["# C | XAI mit ELI5 üë∂\n","---"],"metadata":{"id":"I1AHXekjzbJx"}},{"cell_type":"markdown","source":["**ELI5** = Explain Like I'm 5 (Erkl√§re es mir wie einem 5-J√§hrigen)"],"metadata":{"id":"WjkGOfxFzdbF"}},{"cell_type":"markdown","source":["**Was macht ELI5?**\n","\n","ELI5 ist das **einfachste** XAI-Framework. Es fokussiert sich auf **Permutation Importance** ‚Äì eine intuitive Methode zur Messung der Feature-Wichtigkeit.\n","\n","**Was ist Permutation Importance?**\n","\n","Die Grundidee ist simpel: **Wenn ein Feature wichtig ist, wird das Modell schlechter, wenn wir es \"kaputt machen\".**\n","\n","**So funktioniert es:**\n","1. Miss die Modell-Accuracy auf den Testdaten\n","2. Mische die Werte eines Features zuf√§llig durch (\"permutieren\")\n","3. Miss erneut die Accuracy\n","4. **Differenz** = Wichtigkeit des Features\n","\n","**Beispiel:**\n","- Original-Accuracy: 85%\n","- Accuracy nach Durchmischen von \"Geschlecht\": 65%\n","- ‚Üí Importance(Geschlecht) = 85% - 65% = **20%** (sehr wichtig!)\n","\n","**Warum \"Like I'm 5\"?**\n","\n","- Minimaler Code (oft nur 3 Zeilen)\n","- Keine komplexe Mathematik\n","- Ergebnis ist sofort verst√§ndlich: \"Feature X ist am wichtigsten\"\n","\n","**Einschr√§nkungen**\n","- ‚ö†Ô∏è Zeigt nur **wie wichtig**, nicht **warum** oder **in welche Richtung**\n","- ‚ö†Ô∏è Prim√§r f√ºr **globale** Erkl√§rungen (nicht f√ºr einzelne Vorhersagen)\n"],"metadata":{"id":"HPgtVVCj0xAB"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","‚öôÔ∏è Permutation Importance\n","</font></p>"],"metadata":{"id":"lA6srvKX08ry"}},{"cell_type":"code","source":["# Permutation Importance berechnen\n","perm = PermutationImportance(model, random_state=42).fit(data_test, target_test)"],"metadata":{"id":"AAeYKEH-1Cq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Importance anzeigen\n","eli5.show_weights(perm, feature_names=data.columns.tolist())"],"metadata":{"id":"_fvR3wrO1G-j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üë∞ Rose mit ELI5 erkl√§ren\n","</font></p>\n"],"metadata":{"id":"PjnsKGzC1LaH"}},{"cell_type":"code","source":["# Einzelne Vorhersage erkl√§ren\n","eli5.show_prediction(\n","    model,\n","    rose.iloc[0],\n","    feature_names=rose.columns.tolist(),\n","    show_feature_values=True,\n",")"],"metadata":{"id":"aJU-aBZL1OzE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üé® Jack mit ELI5 erkl√§ren\n","</font></p>\n"],"metadata":{"id":"2ASbNmy61idk"}},{"cell_type":"code","source":["# Einzelne Vorhersage erkl√§ren\n","eli5.show_prediction(\n","    model,\n","    jack.iloc[0],\n","    feature_names=jack.columns.tolist(),\n","    show_feature_values=True,\n","    targets=[1]  # 1 = √úberleben\n",")"],"metadata":{"id":"MU0fk6IW1idl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='blue' size=\"4\">\n","üí° ELI5 Interpretation\n","</font></p>"],"metadata":{"id":"KGiBCDHb1Qyw"}},{"cell_type":"markdown","source":["\n","\n","**Permutation Importance:**\n","- Misst, wie stark die Modell-Accuracy sinkt, wenn ein Feature zuf√§llig permutiert wird\n","- ¬± Werte = Unsicherheit der Messung\n","\n","**Vorhersage-Erkl√§rung:**\n","- Zeigt Feature-Werte und ihre Beitr√§ge zur Vorhersage\n","- Sehr einfach zu verstehen!\n","\n"],"metadata":{"id":"KUxzUp5O1YN7"}},{"cell_type":"markdown","source":["# D | XAI mit InterpretML üè¢\n","---"],"metadata":{"id":"Pza94X-Wzihv"}},{"cell_type":"markdown","source":["**InterpretML** = Microsoft's umfassendes Open-Source-Framework f√ºr XAI"],"metadata":{"id":"9LFJe4mqzksI"}},{"cell_type":"markdown","source":["**Was macht InterpretML?**\n","\n","InterpretML ist das **professionellste** der hier vorgestellten Frameworks. Es kombiniert verschiedene XAI-Methoden unter einer einheitlichen Oberfl√§che und bietet **interaktive Dashboards**.\n","\n","**Kernfunktionen**\n","\n","| Funktion | Beschreibung |\n","|----------|-------------|\n","| **ShapKernel** | SHAP-Erkl√§rungen f√ºr beliebige Black-Box-Modelle |\n","| **Interaktive Dashboards** | Web-basierte Visualisierungen zum Erkunden |\n","| **Unified API** | Gleiche Schnittstelle f√ºr verschiedene Erkl√§rungsmethoden |\n","| **EBM** | Eigenes interpretierbares Modell (Explainable Boosting Machine) |\n","\n","**Wann InterpretML verwenden**?\n","\n","- ‚úÖ Wenn Sie **interaktive Exploration** brauchen\n","- ‚úÖ F√ºr **professionelle Pr√§sentationen** und Berichte\n","- ‚úÖ Wenn Sie **verschiedene XAI-Methoden** vergleichen wollen\n","\n","**Einschr√§nkungen**\n","- ‚ö†Ô∏è Mehr Setup-Aufwand als LIME oder ELI5\n","- ‚ö†Ô∏è Kann f√ºr einfache Aufgaben \"√ºberdimensioniert\" sein\n"],"metadata":{"id":"WR9CbXBB0yg0"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","‚öôÔ∏è InterpretML mit SHAP\n","</font></p>\n"],"metadata":{"id":"y2FIas_74DFx"}},{"cell_type":"code","source":["# SHAP-basierter Explainer in InterpretML\n","interpret_explainer = ShapKernel(\n","    model.predict_proba,\n","    data_train.sample(n=100, random_state=42)\n",")\n","\n","print(\"‚úÖ InterpretML Explainer erstellt\")"],"metadata":{"id":"JTyP-JYE4OD6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üë∞üé® Rose & Jack mit InterpretML\n","</font></p>"],"metadata":{"id":"YdLdK3Vn4Q5I"}},{"cell_type":"markdown","source":["**Was macht `explain_local`?**\n","- Erkl√§rt **lokale** Vorhersagen f√ºr einzelne Instanzen (hier: Rose & Jack)\n","- Verwendet SHAP-Werte im Hintergrund\n","- Zeigt Feature-Beitr√§ge f√ºr jede Person einzeln\n","- Erm√∂glicht interaktiven Vergleich zwischen Instanzen\n"],"metadata":{"id":"UgumWFeh4TtU"}},{"cell_type":"code","source":["# Beide Personen kombinieren\n","rose_jack = DataFrame([rose.iloc[0], jack.iloc[0]], index=[\"Rose\", \"Jack\"])\n","rose_jack_target = [1, 0]  # Rose √ºberlebt, Jack nicht"],"metadata":{"id":"01PsBKrd4Z0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lokale Erkl√§rungen erstellen mit Namen\n","# explain_local liefert:\n","# - Feature-Beitr√§ge f√ºr jede einzelne Instanz\n","# - Interaktive Visualisierung zum Vergleichen\n","# - Basiert auf SHAP-Werten\n","interpret_local = interpret_explainer.explain_local(\n","    rose_jack,\n","    rose_jack_target,\n","    name=\"Rose & Jack Erkl√§rungen\"  # Name f√ºr die Erkl√§rung\n",")\n","\n","# Die Namen werden aus dem DataFrame-Index √ºbernommen\n","print(\"‚úÖ Lokale Erkl√§rungen f√ºr Rose & Jack erstellt\")\n","print(\"   - Zeigt Feature-Beitr√§ge f√ºr jede Person\")\n","print(\"   - Interaktiv vergleichbar im Dashboard\")\n","print(\"   - Namen: Rose (Index 0), Jack (Index 1)\")"],"metadata":{"id":"Nd9Ewcp04dS9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**‚ö†Ô∏è Wichtiger Hinweis zur Auswahl:**       \n","Im Dropdown \"Select Component to Graph\" bedeuten:\n","- **0** = Rose (1. Klasse, weiblich, 22 Jahre)\n","- **1** = Jack (3. Klasse, m√§nnlich, 23 Jahre)"],"metadata":{"id":"x0sOkPN84h1e"}},{"cell_type":"code","source":["# ‚ö†Ô∏è WICHTIG: InterpretML ben√∂tigt JavaScript!\n","# Falls Fehler \"JavaScript-Dateien konnten nicht geladen werden\":\n","#\n","# 1. Chrome: chrome://settings/content/cookies\n","#    ‚Üí \"Drittanbieter-Cookies zulassen\" aktivieren\n","# 2. Firefox: about:preferences#privacy\n","#    ‚Üí Verbesserter Schutz: \"Standard\" statt \"Streng\"\n","# 3. Seite neu laden (Strg+R / Cmd+R)\n","#\n","# Alternative: Verwenden Sie SHAP (Cells oben) - √§hnliche Ergebnisse!\n","\n","# Interaktives Dashboard anzeigen\n","show(interpret_local)"],"metadata":{"id":"MY7EmTKa4pbA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# E | Globale Analysen üåç\n","---"],"metadata":{"id":"YPVjViE14yeA"}},{"cell_type":"markdown","source":["**Lokal vs. Global ‚Äì Was ist der Unterschied?**\n","\n","Bisher haben wir **einzelne Vorhersagen** erkl√§rt (lokal). Jetzt schauen wir uns das **gesamte Modellverhalten** an (global).\n","\n","| Scope | Frage | Beispiel |\n","|-------|-------|----------|\n","| **Lokal** | Warum wurde *diese* Vorhersage gemacht? | Warum √ºberlebt Rose mit 92%? |\n","| **Global** | Wie verh√§lt sich das Modell *insgesamt*? | Welches Feature ist generell am wichtigsten? |"],"metadata":{"id":"iQT8Q_rR44cE"}},{"cell_type":"markdown","source":["\n","\n","**Globale Methoden in diesem Notebook**\n","\n","- **SHAP Summary Plot**: Zeigt die Verteilung der SHAP-Werte √ºber alle Datenpunkte\n","- **SHAP Dependence Plot**: Zeigt, wie ein Feature die Vorhersage √ºber alle Datenpunkte beeinflusst\n","- **RandomForest Feature Importance**: Eingebaute Wichtigkeit basierend auf Entscheidungsb√§umen\n"],"metadata":{"id":"5WITAX0Y5CJQ"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üéØ SHAP Dependence Plot\n","</font></p>\n","\n","**Konzept**: Zeigt, wie die Werte eines Features die Vorhersage beeinflussen.\n"],"metadata":{"id":"75lH5wac48y2"}},{"cell_type":"code","source":["# SHAP Dependence Plot f√ºr das wichtigste Feature (sex)\n","# Zeigt: Wie beeinflusst sex die √úberlebenschance?\n","\n","# Berechne SHAP Werte f√ºr das gesamte Testset\n","test_sample = data_test\n","shap_values_test = shap_explainer(test_sample)\n","\n","shap.dependence_plot(\n","    \"sex\",\n","    shap_values_test[:, :, 1].values,  # SHAP-Werte f√ºr \"Survived\"\n","    test_sample,\n","    interaction_index=\"pclass\"  # Farbe zeigt Interaktion mit pclass\n",")\n","\n","print(\"üí° Interpretation:\")\n","print(\"   - X-Achse: Feature-Wert (0=male, 1=female)\")\n","print(\"   - Y-Achse: SHAP-Wert (Einfluss auf √úberlebenschance)\")\n","print(\"   - Farbe: Interaktion mit pclass (Passagierklasse)\")"],"metadata":{"id":"8MtWqjIf5FCu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üå≤ RandomForest Feature Importance\n","</font></p>\n","\n","**Konzept**: Zeigt, wie oft und wie stark jedes Feature zur Entscheidungsfindung beitr√§gt.\n"],"metadata":{"id":"WKJQd4aH5IxD"}},{"cell_type":"code","source":["# Feature Importance aus RandomForest extrahieren\n","feature_importance = DataFrame({\n","    'Feature': data_train.columns,\n","    'Importance': model.feature_importances_\n","}).sort_values('Importance', ascending=False)\n","\n","# Visualisierung\n","fig = px.bar(\n","    feature_importance,\n","    x='Importance',\n","    y='Feature',\n","    orientation='h',\n","    title='RandomForest Feature Importance (Global)',\n","    labels={'Importance': 'Wichtigkeit', 'Feature': 'Feature'},\n","    color='Importance',\n","    color_continuous_scale='viridis'\n",")\n","fig.update_layout(height=400)\n","fig.show()\n","\n","print(\"\\nüìä Feature Importance Ranking:\")\n","for idx, row in feature_importance.iterrows():\n","    print(f\"  {row['Feature']:10s}: {row['Importance']:.4f}\")"],"metadata":{"id":"7eFDZ-oq5Ot1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# F | Ceteris Paribus Analysen üåç\n","---"],"metadata":{"id":"VwPl5iaW5SZm"}},{"cell_type":"markdown","source":["**Ceteris Paribus** = \"unter sonst gleichen Bedingungen\" (lateinisch)"],"metadata":{"id":"5-ay7_Tg5XJo"}},{"cell_type":"markdown","source":["**Was ist eine Ceteris Paribus Analyse?**\n","\n","Eine Ceteris Paribus Analyse beantwortet die Frage: **\"Was passiert mit der Vorhersage, wenn ich NUR ein Feature √§ndere?\"**\n","\n","Alle anderen Features bleiben dabei konstant ‚Äì daher der Name.\n","\n","**Beispiel**\n","\n","F√ºr Jack (m√§nnlich, 23 Jahre, 3. Klasse) fragen wir:\n","- Was w√§re, wenn Jack in der **1. Klasse** gewesen w√§re? (alle anderen Werte bleiben gleich)\n","- Was w√§re, wenn Jack **50 Jahre** alt gewesen w√§re?\n","\n","**Warum ist das n√ºtzlich?**\n","\n","- üéØ Zeigt den **isolierten Einfluss** einzelner Features\n","- üìä Erm√∂glicht **\"Was-w√§re-wenn\"**-Szenarien\n","- üí° Hilft zu verstehen, **wie das Modell \"denkt\"**\n","\n","**Unterschied zu anderen XAI-Methoden**\n","\n","| Methode | Frage |\n","|---------|-------|\n","| **SHAP/LIME** | Welche Features haben diese Vorhersage beeinflusst? |\n","| **Ceteris Paribus** | Wie √§ndert sich die Vorhersage, wenn ich ein Feature variiere? |\n","\n","**Erkenntnisse:**\n","1. **Alter**: J√ºngere Personen hatten tendenziell h√∂here √úberlebenschancen (\"Women and children first\")\n","2. **Passagierklasse**: 1. Klasse hatte deutlich h√∂here √úberlebenschancen\n","3. **Geschlecht dominiert**: Selbst Jack in 1. Klasse h√§tte schlechtere Chancen als Rose in 3. Klasse!\n"],"metadata":{"id":"Imw0hTRi5bt0"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üé® Individual Ceteris Paribus: Jack\n","</font></p>\n","\n","**Was w√§re wenn**: Jack in verschiedenen Passagierklassen gereist w√§re?"],"metadata":{"id":"DiRLwzJo5eMT"}},{"cell_type":"code","source":["# Ceteris Paribus f√ºr Jack: Was passiert in verschiedenen Klassen?\n","jack_cp = jack.copy()\n","\n","pclass_original = [1, 2, 3]\n","jack_predictions = []\n","\n","for pclass in pclass_original:\n","    jack_cp['pclass'] = pclass\n","    pred = model.predict_proba(jack_cp)[0][1] * 100\n","    jack_predictions.append(pred)\n","\n","# Visualisierung\n","fig = px.bar(\n","    x=['1. Klasse', '2. Klasse', '3. Klasse (Jack)'],\n","    y=jack_predictions,\n","    labels={'x': 'Passagierklasse', 'y': '√úberlebenschance (%)'},\n","    title='Ceteris Paribus: Jack - Einfluss der Passagierklasse',\n","    color=jack_predictions,\n","    color_continuous_scale='RdYlGn'\n",")\n","fig.show()\n","\n","print(\"üí° Interpretation:\")\n","print(f\"   Jack in 1. Klasse: {jack_predictions[0]:.2f}%\")\n","print(f\"   Jack in 2. Klasse: {jack_predictions[1]:.2f}%\")\n","print(f\"   Jack in 3. Klasse: {jack_predictions[2]:.2f}% (aktuell)\")\n","print(\"\\n   ‚ö†Ô∏è Selbst in 1. Klasse w√ºrde Jack's m√§nnliches Geschlecht seine Chancen stark begrenzen!\")"],"metadata":{"id":"XX1uCPEy5oo1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üë∞ Individual Ceteris Paribus: Rose\n","</font></p>\n","\n","**Was w√§re wenn**:  Was passiert, wenn wir ihr Alter variieren??"],"metadata":{"id":"5IRyYLGX5tX6"}},{"cell_type":"code","source":["# Ceteris Paribus f√ºr Rose: Was passiert, wenn wir ihr Alter variieren?\n","# Alle anderen Features bleiben konstant\n","\n","age_range = range(0, 80,1)  # Skalierte Werte (StandardScaler)\n","rose_cp = rose.copy()\n","\n","predictions = []\n","for age_val in age_range:\n","    rose_cp['age'] = age_val\n","    pred = model.predict_proba(rose_cp)[0][1] * 100\n","    predictions.append(pred)\n","\n","# Visualisierung\n","fig = px.line(\n","    x=age_range,\n","    y=predictions,\n","    labels={'x': 'Alter', 'y': '√úberlebenschance (%)'},\n","    title='Ceteris Paribus: Rose - Einfluss des Alters'\n",")\n","fig.add_vline(x=rose.iloc[0]['age'], line_dash=\"dash\", line_color=\"red\",\n","              annotation_text=\"Rose aktuell\")\n","fig.show()\n","\n","print(f\"üí° Rose's aktuelles Alter (skaliert): {rose.iloc[0]['age']:.2f}\")\n","print(f\"   Aktuelle √úberlebenschance: {rose_pred:.2f}%\")\n","print(f\"   Interpretation: Je j√ºnger Rose, desto h√∂her ihre √úberlebenschance\")"],"metadata":{"id":"PfGXo6nM5zKk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# G | Zusammenfassung üî¨\n","---"],"metadata":{"id":"YOurdh5T55kA"}},{"cell_type":"markdown","source":["| Framework | üéØ St√§rken | ‚ö†Ô∏è Schw√§chen | üë®‚Äçüéì Einsteigerfreundlichkeit |\n","|-----------|-----------|-------------|---------------------------|\n","| **LIME** | - Sehr intuitives Konzept<br>- Gute visuelle Darstellung<br>- Schnell f√ºr lokale Erkl√§rungen | - Nur lokale Erkl√§rungen<br>- Kann instabil sein | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n","| **SHAP** | - Theoretisch fundiert<br>- Beste Visualisierungen<br>- Lokal & global | - Kann langsam sein<br>- Komplexeres Konzept | ‚≠ê‚≠ê‚≠ê‚≠ê |\n","| **ELI5** | - Extrem einfach<br>- Minimaler Code<br>- Schnell | - Weniger Visualisierungen<br>- Weniger Features | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n","| **InterpretML** | - Interaktive Dashboards<br>- Umfassend<br>- Professionell | - Komplexer Setup<br>- Overhead f√ºr einfache Aufgaben | ‚≠ê‚≠ê‚≠ê |\n","| **RF Importance** | - Extrem schnell<br>- In sklearn integriert<br>- Sehr einfach | - Nur Feature Importance<br>- Keine Richtung des Einflusses | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n"],"metadata":{"id":"P2qmr3ut59YW"}},{"cell_type":"markdown","source":["\n","**üîó Weiterf√ºhrende Ressourcen**\n","\n","**LIME:**\n","- Dokumentation: https://github.com/marcotcr/lime\n","- Paper: \"Why Should I Trust You?\" (Ribeiro et al., 2016)\n","\n","**SHAP:**\n","- Dokumentation: https://shap.readthedocs.io/\n","- Paper: \"A Unified Approach to Interpreting Model Predictions\" (Lundberg & Lee, 2017)\n","\n","**ELI5:**\n","- Dokumentation: https://eli5.readthedocs.io/\n","\n","**InterpretML:**\n","- Dokumentation: https://interpret.ml/\n","- Microsoft Research: https://www.microsoft.com/en-us/research/project/interpretml/\n","\"\"\""],"metadata":{"id":"eGSYL3_46D-K"}}]}