{"cells":[{"cell_type":"markdown","metadata":{"id":"uwkRYt0YUm4l"},"source":["<p><font size=\"6\" color='grey'> <b>\n","Machine Learning\n","</b></font> </br></p>\n","<p><font size=\"5\" color='grey'> <b>\n","XAI Frameworks im Vergleich - Titanic\n","</b></font> </br></p>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"LlwV3BJ6Um4m"},"source":["**Explainable AI (XAI) Frameworks:**\n","\n","- üîç **LIME** - Local Interpretable Model-agnostic Explanations\n","- üéØ **SHAP** - SHapley Additive exPlanations  \n","- üë∂ **ELI5** - Explain Like I'm 5\n","- üè¢ **InterpretML** - Microsoft's umfassendes Framework\n","\n","Dieses Notebook vergleicht alle wichtigen XAI-Frameworks am Titanic-Datensatz.\n","\n","---\n","\n","**üìö Wichtige Begriffe f√ºr dieses Notebook:**\n","\n","| Begriff | Bedeutung |\n","|---------|----------|\n","| **Black-Box-Modell** | ML-Modell, dessen Entscheidungslogik nicht direkt einsehbar ist (z.B. Random Forest, neuronale Netze) |\n","| **Modell-agnostisch** | Die Methode funktioniert bei jedem Modelltyp ‚Äì egal ob Random Forest, XGBoost oder neuronales Netz |\n","| **Lokal vs. Global** | Lokal = erkl√§rt eine einzelne Vorhersage; Global = erkl√§rt das gesamte Modellverhalten |\n","| **Feature Importance** | Wie wichtig ist ein Merkmal f√ºr die Vorhersage? |\n","| **Perturbation** | Gezieltes Ver√§ndern von Eingabewerten, um deren Einfluss zu messen |"]},{"cell_type":"markdown","metadata":{"id":"yztPphbhUm4n"},"source":["# 0  | Install & Import\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzTj-ClQUm4n"},"outputs":[],"source":["# Install\n","!uv pip install --system -q shap lime eli5 interpret plotly\n","!uv pip install -q git+https://github.com/parrt/dtreeviz.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0VTwXr1Um4o"},"outputs":[],"source":["# Import\n","from pandas import read_excel, DataFrame\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# XAI Frameworks\n","import shap\n","import lime\n","from lime.lime_tabular import LimeTabularExplainer\n","import eli5\n","from eli5.sklearn import PermutationImportance\n","from interpret import show\n","from interpret.blackbox import ShapKernel\n","\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","import dtreeviz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42cFJmssUm4o"},"outputs":[],"source":["# Warnung ausstellen\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Matplotlib-spezifische Warnungen unterdr√ºcken\n","import logging\n","logging.getLogger('matplotlib').setLevel(logging.ERROR)"]},{"cell_type":"markdown","metadata":{"id":"uUX9NoXDUm4o"},"source":["# 1  | Understand\n","***"]},{"cell_type":"markdown","metadata":{"id":"hFRNv2_3Um4p"},"source":["<p><font color='black' size=\"5\">\n","üìí Anwendungsfall\n","</font></p>\n","\n","Der legend√§re Titanic ML-Wettbewerb: Vorhersage, welche Passagiere √ºberlebt haben.\n","\n","**Ziel**: Vergleich verschiedener XAI-Frameworks zur Erkl√§rung der Modellvorhersagen.\n","\n","**Beispielpersonen:**\n","- üë∞ **Rose DeWitt Bukater** (Kate Winslet) - 1. Klasse, weiblich, 22 Jahre\n","- üé® **Jack Dawson** (Leonardo DiCaprio) - 3. Klasse, m√§nnlich, 23 Jahre"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsxKGk8aUm4p"},"outputs":[],"source":["df = read_excel(\n","    \"https://raw.githubusercontent.com/ralf-42/ML_Intro/main/02_daten/05_tabellen/titanic.xlsx\",\n","    usecols=[\"pclass\", \"survived\", \"sex\", \"age\", \"sibsp\", \"parch\"],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LpUA1ziUm4q"},"outputs":[],"source":["data = df.copy()\n","target = data.pop(\"survived\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zchz-U7bUm4q"},"outputs":[],"source":["data.head()"]},{"cell_type":"markdown","metadata":{"id":"W9kLafCVUm4q"},"source":["# 2 | Prepare\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"F5zGSHB5Um4q"},"source":["<p><font color='black' size=\"5\">\n","üî¢ Features anzeigen\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4jugUO8Um4q"},"outputs":[],"source":["all_col = data.columns\n","num_col = ['age', 'sibsp', 'parch', 'pclass']  # Numerische Features\n","cat_col = ['sex']  # Kategorische Features\n","\n","print(f\"Numerische Features: {num_col}\")\n","print(f\"Kategorische Features: {cat_col}\")\n","print(f\"Alle Features: {list(all_col)}\")"]},{"cell_type":"markdown","metadata":{"id":"PZQXZlHvUm4r"},"source":["<p><font color='black' size=\"5\">\n","‚öôÔ∏è Manuelle Vorverarbeitung\n","</font></p>\n","\n","‚ö†Ô∏è **Wichtig**: RandomForest ben√∂tigt KEINE Skalierung! Tree-basierte Modelle sind invariant gegen√ºber monotonen Transformationen."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vuduyrNyUm4r"},"outputs":[],"source":["# Kopie der Daten erstellen\n","data_processed = data.copy()\n","\n","# 1. Kategorische Variable kodieren: sex (male=0, female=1)\n","data_processed['sex'] = data_processed['sex'].map({'male': 0, 'female': 1})\n","\n","# 2. Missing Values in age mit Mittelwert f√ºllen\n","age_mean = data_processed['age'].mean()\n","data_processed['age'].fillna(age_mean, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"1uETnjuBUm4r"},"source":["<p><font color='black' size=\"5\">\n","‚úÇÔ∏è Train-Test-Split\n","</font></p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"quiaa2AAUm4r"},"outputs":[],"source":["data_train, data_test, target_train, target_test = train_test_split(\n","    data_processed, target, test_size=0.20, random_state=42, stratify=target\n",")\n","\n","print(f\"Train: {data_train.shape}, Test: {data_test.shape}\")\n","print(f\"Features: {list(data_train.columns)}\")"]},{"cell_type":"markdown","metadata":{"id":"M4KR7HM7Um4r"},"source":["# 3 | Modeling\n","---"]},{"cell_type":"markdown","metadata":{"id":"_rGP5GW6Um4r"},"source":["<p><font color='black' size=\"5\">\n","üèÉ Modellauswahl & Training\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_6NuV2CUm4r"},"outputs":[],"source":["# RandomForestClassifier mit optimierten Hyperparametern (ohne Pipeline!)\n","# Reduziert Overfitting durch:\n","# - Mehr B√§ume (n_estimators=200)\n","# - Weniger tiefe B√§ume (max_depth=5)\n","# - Gr√∂√üere Mindestanzahl pro Blatt (min_samples_leaf=5)\n","# - Gr√∂√üere Mindestanzahl f√ºr Split (min_samples_split=10)\n","\n","model = RandomForestClassifier(\n","    n_estimators=200,        # Mehr B√§ume f√ºr stabilere Vorhersagen\n","    max_depth=5,             # Weniger tief = weniger Overfitting\n","    min_samples_split=10,    # Mind. 10 Samples f√ºr Split\n","    min_samples_leaf=5,      # Mind. 5 Samples pro Blatt\n","    max_features='sqrt',     # Nur Wurzel der Features pro Split\n","    random_state=42\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMlmCoBSUm4r"},"outputs":[],"source":["model.fit(data_train, target_train)"]},{"cell_type":"markdown","metadata":{"id":"GVxyDGMWUm4s"},"source":["# 4 | Evaluate\n","---"]},{"cell_type":"markdown","metadata":{"id":"24o7jmf6Um4s"},"source":["<p><font color='black' size=\"5\">\n","üéØ Accuracy\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAAZ8pPEUm4s"},"outputs":[],"source":["target_train_pred = model.predict(data_train)\n","target_test_pred = model.predict(data_test)\n","\n","acc_train = accuracy_score(target_train, target_train_pred) * 100\n","acc_test = accuracy_score(target_test, target_test_pred) * 100\n","\n","print(f\"Train Accuracy: {acc_train:5.2f}%\")\n","print(f\"Test Accuracy:  {acc_test:5.2f}%\")"]},{"cell_type":"markdown","metadata":{"id":"JtIEcoPRUm4s"},"source":["<p><font color='black' size=\"5\">\n","üìù Testpersonen: Rose & Jack\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zt2BqHi5Um4s"},"outputs":[],"source":["# Rose DeWitt Bukater (Kate Winslet) - Original-Werte (keine Skalierung!)\n","rose = DataFrame(\n","    {\"age\": [22], \"sex\": [1], \"sibsp\": [0], \"parch\": [1], \"pclass\": [1]},  # sex=1 (female)\n","    index=[\"Rose\"],\n",")\n","\n","# Jack Dawson (Leonardo DiCaprio) - Original-Werte (keine Skalierung!)\n","jack = DataFrame(\n","    {\"age\": [23], \"sex\": [0], \"sibsp\": [0], \"parch\": [0], \"pclass\": [3]},  # sex=0 (male)\n","    index=[\"Jack\"],\n",")\n","\n","rose_pred = model.predict_proba(rose)[0][1] * 100\n","jack_pred = model.predict_proba(jack)[0][1] * 100\n","\n","print(f\"üë∞ Rose √úberlebenschance: {rose_pred:.2f}%\")\n","print(f\"   (22 Jahre, weiblich, 1. Klasse)\")\n","print(f\"üé® Jack √úberlebenschance: {jack_pred:.2f}%\")\n","print(f\"   (23 Jahre, m√§nnlich, 3. Klasse)\")"]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üå≥ Entscheidungsbaum Visualisierung\n","</font></p>\n","\n","**Hinweis**: RandomForest besteht aus 200 B√§umen. Hier wird nur der ersten Baum als Beispiel visualisiert."],"metadata":{"id":"VZnGPBe9drjG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KmhvTpEl6QWd"},"outputs":[],"source":["# Extrahiere den ersten Baum aus dem RandomForest\n","single_tree = model.estimators_[1]\n","\n","# Erstelle dtreeviz Visualisierung f√ºr diesen einzelnen Baum\n","viz_model = dtreeviz.model(\n","    single_tree,\n","    X_train=data_train,\n","    y_train=target_train,\n","    target_name=\"survived\",\n","    class_names=[\"not survived\", \"survived\"],\n","    feature_names=list(data_train.columns),\n",")\n","\n","print(f\"‚úÖ Visualisierung f√ºr Baum 1 von {model.n_estimators} erstellt\")"]},{"cell_type":"code","source":["# Visualisierung anzeigen\n","viz_model.view(scale=1.0, fontname=\"Monospace\")"],"metadata":{"id":"37thk_lil2lN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# local Explanation - total\n","one = rose.iloc[0].values\n","viz_model.view(x=one, scale=1.0,fontname=\"Monospace\")"],"metadata":{"id":"Eig4cFfZpbyZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hY315AkLUm4s"},"source":["# 5 | Deploy\n","---"]},{"cell_type":"markdown","metadata":{"id":"SQfX_4PoUm4s"},"source":["# A | XAI mit LIME üîç\n","---\n","\n","**LIME** = Local Interpretable Model-agnostic Explanations\n","\n","### Was macht LIME?\n","\n","LIME erkl√§rt **einzelne Vorhersagen**, indem es ein einfaches, verst√§ndliches Modell lokal um den zu erkl√§renden Datenpunkt herum trainiert.\n","\n","### Wie funktioniert LIME?\n","\n","1. **Perturbation**: LIME erzeugt viele leicht ver√§nderte Versionen des Datenpunkts (z.B. Alter ¬±5 Jahre, andere Klasse)\n","2. **Vorhersagen sammeln**: Das Black-Box-Modell bewertet alle perturbierten Samples\n","3. **Gewichtung**: Samples, die dem Original √§hnlicher sind, bekommen mehr Gewicht\n","4. **Lokales Modell**: Ein einfaches lineares Modell wird auf diese gewichteten Samples trainiert\n","5. **Interpretation**: Die Koeffizienten des linearen Modells zeigen den Einfluss jedes Features\n","\n","### Warum \"lokal\"?\n","\n","LIME erkl√§rt nicht das gesamte Modell, sondern nur die **unmittelbare Umgebung** eines Datenpunkts. Die Erkl√§rung f√ºr Rose kann v√∂llig anders aussehen als die f√ºr Jack.\n","\n","### Vorteile\n","- ‚úÖ Funktioniert mit **jedem** Modell (modell-agnostisch)\n","- ‚úÖ Sehr **intuitiv** zu verstehen\n","- ‚úÖ **Schnell** f√ºr einzelne Vorhersagen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHZHn8mJUm4s"},"outputs":[],"source":["# LIME Explainer mit vorverarbeiteten Daten erstellen\n","lime_explainer = LimeTabularExplainer(\n","    data_train.values,\n","    feature_names=data_train.columns.tolist(),\n","    class_names=['Not Survived', 'Survived'],\n","    categorical_features=[0, 4],  # pclass (Index 0) und sex (Index 4) sind kategorisch\n","    mode='classification'\n",")\n","\n","print(\"‚úÖ LIME Explainer erstellt\")\n","print(\"   Features:\", data_train.columns.tolist())"]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üë∞ Rose mit LIME erkl√§ren\n","</font></p>"],"metadata":{"id":"YqaTbZ5uWNKA"}},{"cell_type":"code","source":["# Rose mit LIME erkl√§ren (direkt, ohne Wrapper!)\n","rose_lime_exp = lime_explainer.explain_instance(\n","    rose.iloc[0].values,\n","    model.predict_proba,  # Direkt das Modell verwenden!\n","    num_features=5\n",")\n","\n","rose_lime_exp.show_in_notebook(show_table=True)"],"metadata":{"id":"jw4NS1hBWNKB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BLCrUgTGUm4s"},"source":["<p><font color='black' size=\"5\">\n","üé® Jack mit LIME erkl√§ren\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T6wy5rnCUm4t"},"outputs":[],"source":["# Jack mit LIME erkl√§ren (direkt, ohne Wrapper!)\n","jack_lime_exp = lime_explainer.explain_instance(\n","    jack.iloc[0].values,\n","    model.predict_proba,  # Direkt das Modell verwenden!\n","    num_features=5\n",")\n","\n","jack_lime_exp.show_in_notebook(show_table=True)"]},{"cell_type":"markdown","metadata":{"id":"oQxWaRlaUm4t"},"source":["<p><font color='blue' size=\"4\">\n","üí° LIME Interpretation\n","</font></p>\n","\n","**Balkendiagramm:**\n","- **Orange Balken**: Erh√∂hen die √úberlebenschance (Klasse \"Survived\")\n","- **Blaue Balken**: Verringern die √úberlebenschance (Klasse \"Not Survived\")\n","- **Werte**: Wie stark beeinflusst das Feature die Vorhersage\n","\n","**PrScore (Prediction Score) Tabelle:**\n","- Zeigt die Vorhersage-Wahrscheinlichkeit f√ºr **beide Klassen**\n","- **Not Survived**: Wahrscheinlichkeit f√ºr Tod (h√∂her bei Jack)\n","- **Survived**: Wahrscheinlichkeit f√ºr √úberleben (h√∂her bei Rose)\n","- Beide Werte zusammen ergeben immer 100%\n","\n","**Beispiel:**\n","- Rose: Not Survived ‚âà 35%, **Survived ‚âà 65%**\n","- Jack: **Not Survived ‚âà 93%**, Survived ‚âà 7%\n","\n","‚ö†Ô∏è **Wichtig**: Der PrScore f√ºr \"Not Survived\" ist bei Jack h√∂her - das bedeutet er hat eine h√∂here Todeswahrscheinlichkeit, nicht eine h√∂here √úberlebenschance!\n","\n","**Erkenntnisse:**\n","- Rose: `sex=1` (female) und `pclass=1` erh√∂hen massiv die √úberlebenschance\n","- Jack: `sex=0` (male) und `pclass=3` verringern massiv die √úberlebenschance\n","\n","‚úÖ **Vorteil ohne Pipeline**: Viel einfacher! Nur 3 Zeilen Code statt komplexer Wrapper-Funktion."]},{"cell_type":"markdown","metadata":{"id":"95Ky-ds8Um4t"},"source":["# B | XAI mit SHAP üéØ\n","---\n","\n","**SHAP** = SHapley Additive exPlanations\n","\n","### Was macht SHAP?\n","\n","SHAP berechnet den **Beitrag jedes Features** zur Vorhersage, basierend auf einem mathematisch fundierten Konzept aus der Spieltheorie.\n","\n","### Die Spieltheorie-Idee (vereinfacht)\n","\n","Stellen Sie sich ein Team von Spielern vor, das gemeinsam einen Preis gewinnt. Wie verteilt man den Gewinn **fair**? Die Shapley-Werte l√∂sen genau dieses Problem.\n","\n","**√úbertragen auf ML:**\n","- **Spieler** = Features (Alter, Geschlecht, Klasse, ...)\n","- **Gewinn** = Vorhersage des Modells\n","- **Frage**: Wie viel tr√§gt jedes Feature zur Vorhersage bei?\n","\n","### Wie funktioniert SHAP?\n","\n","1. Betrachte **alle m√∂glichen Kombinationen** von Features\n","2. Berechne f√ºr jede Kombination: Was √§ndert sich, wenn ich Feature X hinzuf√ºge?\n","3. Der **Durchschnitt** √ºber alle Kombinationen = SHAP-Wert des Features\n","\n","### Interpretation der SHAP-Werte\n","\n","| SHAP-Wert | Bedeutung |\n","|-----------|----------|\n","| **Positiv (+)** | Feature erh√∂ht die Vorhersage (hier: √úberlebenschance) |\n","| **Negativ (-)** | Feature senkt die Vorhersage |\n","| **Nahe 0** | Feature hat wenig Einfluss auf diese Vorhersage |\n","\n","### Vorteile gegen√ºber LIME\n","- ‚úÖ **Theoretisch fundiert** ‚Äì mathematisch beweisbar fair\n","- ‚úÖ Funktioniert **lokal und global**\n","- ‚úÖ Die Summe aller SHAP-Werte ergibt die Vorhersage"]},{"cell_type":"markdown","metadata":{"id":"phKZhWteUm4t"},"source":["<p><font color='black' size=\"5\">\n","‚öôÔ∏è SHAP Explainer erstellen\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zCOp3zyZUm4t"},"outputs":[],"source":["# SHAP TreeExplainer (optimal f√ºr RandomForest - sehr schnell!)\n","shap_explainer = shap.TreeExplainer(model)\n","\n","print(\"‚úÖ SHAP TreeExplainer erstellt (optimiert f√ºr RandomForest)\")"]},{"cell_type":"markdown","metadata":{"id":"gAuW-RmvUm45"},"source":["<p><font color='black' size=\"5\">\n","üë∞ Rose mit SHAP erkl√§ren (Waterfall Plot)\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cuvTa37hUm46"},"outputs":[],"source":["rose_shap = shap_explainer(rose)\n","\n","# Waterfall Plot f√ºr Klasse \"Survived\" (Index 1)\n","shap.plots.waterfall(rose_shap[0, :, 1])"]},{"cell_type":"markdown","metadata":{"id":"V8jDVcfKUm46"},"source":["<p><font color='black' size=\"5\">\n","üé® Jack mit SHAP erkl√§ren (Waterfall Plot)\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGD2FpR0Um46"},"outputs":[],"source":["jack_shap = shap_explainer(jack)\n","\n","# Waterfall Plot f√ºr Klasse \"Survived\" (Index 1)\n","shap.plots.waterfall(jack_shap[0, :, 1])"]},{"cell_type":"markdown","metadata":{"id":"9yfSj45dUm46"},"source":["<p><font color='black' size=\"5\">\n","üìä SHAP Summary Plot (alle Testdaten)\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XIEzWwlQUm46"},"outputs":[],"source":["# SHAP-Werte f√ºr Testdaten berechnen (Sample f√ºr Performance)\n","test_sample = data_test.sample(n=50, random_state=42)\n","shap_values_test = shap_explainer(test_sample)\n","\n","# Summary Plot f√ºr Klasse \"Survived\" (Index 1)\n","shap.summary_plot(shap_values_test[:, :, 1], test_sample, plot_type=\"bar\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBaL2PZRUm46"},"outputs":[],"source":["# Beeswarm Plot (detaillierter)\n","shap.summary_plot(shap_values_test[:, :, 1], test_sample)"]},{"cell_type":"markdown","metadata":{"id":"Xr1MYeh1Um46"},"source":["<p><font color='blue' size=\"4\">\n","üí° SHAP Interpretation\n","</font></p>\n","\n","**Waterfall Plot:**\n","- Zeigt, wie sich die Vorhersage vom Durchschnittswert (E[f(x)]) zum finalen Wert aufbaut\n","- Jeder Pfeil = Beitrag eines Features\n","- Rot = erh√∂ht die √úberlebenschance, Blau = verringert sie\n","\n","**Summary Plot:**\n","- **Bar**: Durchschnittliche absolute SHAP-Werte = Feature Importance\n","- **Beeswarm**: Jeder Punkt ist eine Vorhersage, Farbe = Feature-Wert"]},{"cell_type":"markdown","metadata":{"id":"LqLR7CT_Um46"},"source":["# C | XAI mit ELI5 üë∂\n","---\n","\n","**ELI5** = Explain Like I'm 5 (Erkl√§re es mir wie einem 5-J√§hrigen)\n","\n","### Was macht ELI5?\n","\n","ELI5 ist das **einfachste** XAI-Framework. Es fokussiert sich auf **Permutation Importance** ‚Äì eine intuitive Methode zur Messung der Feature-Wichtigkeit.\n","\n","### Was ist Permutation Importance?\n","\n","Die Grundidee ist simpel: **Wenn ein Feature wichtig ist, wird das Modell schlechter, wenn wir es \"kaputt machen\".**\n","\n","**So funktioniert es:**\n","1. Miss die Modell-Accuracy auf den Testdaten\n","2. Mische die Werte eines Features zuf√§llig durch (\"permutieren\")\n","3. Miss erneut die Accuracy\n","4. **Differenz** = Wichtigkeit des Features\n","\n","**Beispiel:**\n","- Original-Accuracy: 85%\n","- Accuracy nach Durchmischen von \"Geschlecht\": 65%\n","- ‚Üí Importance(Geschlecht) = 85% - 65% = **20%** (sehr wichtig!)\n","\n","### Warum \"Like I'm 5\"?\n","\n","- Minimaler Code (oft nur 3 Zeilen)\n","- Keine komplexe Mathematik\n","- Ergebnis ist sofort verst√§ndlich: \"Feature X ist am wichtigsten\"\n","\n","### Einschr√§nkungen\n","- ‚ö†Ô∏è Zeigt nur **wie wichtig**, nicht **warum** oder **in welche Richtung**\n","- ‚ö†Ô∏è Prim√§r f√ºr **globale** Erkl√§rungen (nicht f√ºr einzelne Vorhersagen)"]},{"cell_type":"markdown","metadata":{"id":"GAOHdAIBUm46"},"source":["<p><font color='black' size=\"5\">\n","‚öôÔ∏è Permutation Importance\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_D-nnUZEUm46"},"outputs":[],"source":["# Permutation Importance berechnen\n","perm = PermutationImportance(model, random_state=42).fit(data_test, target_test)\n","\n","# Feature Importance anzeigen\n","eli5.show_weights(perm, feature_names=data.columns.tolist())"]},{"cell_type":"markdown","metadata":{"id":"i0HV5zRxUm47"},"source":["<p><font color='black' size=\"5\">\n","üë∞ Rose mit ELI5 erkl√§ren\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROnd7896Um47"},"outputs":[],"source":["# Einzelne Vorhersage erkl√§ren\n","eli5.show_prediction(\n","    model,\n","    rose.iloc[0],\n","    feature_names=rose.columns.tolist(),\n","    show_feature_values=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"cFLpbNOuUm47"},"source":["<p><font color='blue' size=\"4\">\n","üí° ELI5 Interpretation\n","</font></p>\n","\n","**Permutation Importance:**\n","- Misst, wie stark die Modell-Accuracy sinkt, wenn ein Feature zuf√§llig permutiert wird\n","- ¬± Werte = Unsicherheit der Messung\n","\n","**Vorhersage-Erkl√§rung:**\n","- Zeigt Feature-Werte und ihre Beitr√§ge zur Vorhersage\n","- Sehr einfach zu verstehen!"]},{"cell_type":"markdown","metadata":{"id":"J45xXngSUm47"},"source":["# D | XAI mit InterpretML üè¢\n","---\n","\n","**InterpretML** = Microsoft's umfassendes Open-Source-Framework f√ºr XAI\n","\n","### Was macht InterpretML?\n","\n","InterpretML ist das **professionellste** der hier vorgestellten Frameworks. Es kombiniert verschiedene XAI-Methoden unter einer einheitlichen Oberfl√§che und bietet **interaktive Dashboards**.\n","\n","### Kernfunktionen\n","\n","| Funktion | Beschreibung |\n","|----------|-------------|\n","| **ShapKernel** | SHAP-Erkl√§rungen f√ºr beliebige Black-Box-Modelle |\n","| **Interaktive Dashboards** | Web-basierte Visualisierungen zum Erkunden |\n","| **Unified API** | Gleiche Schnittstelle f√ºr verschiedene Erkl√§rungsmethoden |\n","| **EBM** | Eigenes interpretierbares Modell (Explainable Boosting Machine) |\n","\n","### Wann InterpretML verwenden?\n","\n","- ‚úÖ Wenn Sie **interaktive Exploration** brauchen\n","- ‚úÖ F√ºr **professionelle Pr√§sentationen** und Berichte\n","- ‚úÖ Wenn Sie **verschiedene XAI-Methoden** vergleichen wollen\n","\n","### Einschr√§nkungen\n","- ‚ö†Ô∏è Mehr Setup-Aufwand als LIME oder ELI5\n","- ‚ö†Ô∏è Kann f√ºr einfache Aufgaben \"√ºberdimensioniert\" sein"]},{"cell_type":"markdown","metadata":{"id":"LLDA9TwvUm47"},"source":["<p><font color='black' size=\"5\">\n","‚öôÔ∏è InterpretML mit SHAP\n","</font></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szoY7k0QUm47"},"outputs":[],"source":["# SHAP-basierter Explainer in InterpretML\n","interpret_explainer = ShapKernel(\n","    model.predict_proba,\n","    data_train.sample(n=100, random_state=42)\n",")\n","\n","print(\"‚úÖ InterpretML Explainer erstellt\")"]},{"cell_type":"markdown","metadata":{"id":"FdJHkKe0Um47"},"source":["<p><font color='black' size=\"5\">\n","üë∞üé® Rose & Jack mit InterpretML\n","</font></p>\n","\n","**Was macht `explain_local`?**\n","- Erkl√§rt **lokale** Vorhersagen f√ºr einzelne Instanzen (hier: Rose & Jack)\n","- Verwendet SHAP-Werte im Hintergrund\n","- Zeigt Feature-Beitr√§ge f√ºr jede Person einzeln\n","- Erm√∂glicht interaktiven Vergleich zwischen Instanzen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PhwSc9aBUm47"},"outputs":[],"source":["# Beide Personen kombinieren\n","rose_jack = DataFrame([rose.iloc[0], jack.iloc[0]], index=[\"Rose\", \"Jack\"])\n","rose_jack_target = [1, 0]  # Rose √ºberlebt, Jack nicht\n","\n","# Lokale Erkl√§rungen erstellen mit Namen\n","# explain_local liefert:\n","# - Feature-Beitr√§ge f√ºr jede einzelne Instanz\n","# - Interaktive Visualisierung zum Vergleichen\n","# - Basiert auf SHAP-Werten\n","interpret_local = interpret_explainer.explain_local(\n","    rose_jack,\n","    rose_jack_target,\n","    name=\"Rose & Jack Erkl√§rungen\"  # Name f√ºr die Erkl√§rung\n",")\n","\n","# Die Namen werden aus dem DataFrame-Index √ºbernommen\n","print(\"‚úÖ Lokale Erkl√§rungen f√ºr Rose & Jack erstellt\")\n","print(\"   - Zeigt Feature-Beitr√§ge f√ºr jede Person\")\n","print(\"   - Interaktiv vergleichbar im Dashboard\")\n","print(\"   - Namen: Rose (Index 0), Jack (Index 1)\")"]},{"cell_type":"markdown","source":["**‚ö†Ô∏è Wichtiger Hinweis zur Auswahl:**\n","Im Dropdown \"Select Component to Graph\" bedeuten:\n","- **0** = Rose (1. Klasse, weiblich, 22 Jahre)\n","- **1** = Jack (3. Klasse, m√§nnlich, 23 Jahre)"],"metadata":{"id":"EnqXaDA1kCtZ"}},{"cell_type":"code","source":["# Interaktives Dashboard anzeigen\n","# Das Dashboard zeigt:\n","# - Links: Dropdown zur Auswahl zwischen Rose und Jack\n","# - Rechts: Feature-Beitr√§ge als Balkendiagramm\n","# - Hover: Details zu jedem Feature\n","show(interpret_local)"],"metadata":{"id":"yWhbssXVcrNL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# E | Globale Analysen üåç\n","---\n","\n","### Lokal vs. Global ‚Äì Was ist der Unterschied?\n","\n","Bisher haben wir **einzelne Vorhersagen** erkl√§rt (lokal). Jetzt schauen wir uns das **gesamte Modellverhalten** an (global).\n","\n","| Scope | Frage | Beispiel |\n","|-------|-------|----------|\n","| **Lokal** | Warum wurde *diese* Vorhersage gemacht? | Warum √ºberlebt Rose mit 92%? |\n","| **Global** | Wie verh√§lt sich das Modell *insgesamt*? | Welches Feature ist generell am wichtigsten? |\n","\n","### Globale Methoden in diesem Notebook\n","\n","- **SHAP Summary Plot**: Zeigt die Verteilung der SHAP-Werte √ºber alle Datenpunkte\n","- **SHAP Dependence Plot**: Zeigt, wie ein Feature die Vorhersage √ºber alle Datenpunkte beeinflusst\n","- **RandomForest Feature Importance**: Eingebaute Wichtigkeit basierend auf Entscheidungsb√§umen"],"metadata":{"id":"UOftpSlthoi8"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üéØ SHAP Dependence Plot\n","</font></p>\n","\n","**Konzept**: Zeigt, wie die Werte eines Features die Vorhersage beeinflussen."],"metadata":{"id":"GKp0rpTUhoi8"}},{"cell_type":"code","source":["# SHAP Dependence Plot f√ºr das wichtigste Feature (sex)\n","# Zeigt: Wie beeinflusst sex die √úberlebenschance?\n","\n","shap.dependence_plot(\n","    \"sex\",\n","    shap_values_test[:, :, 1].values,  # SHAP-Werte f√ºr \"Survived\"\n","    test_sample,\n","    interaction_index=\"pclass\"  # Farbe zeigt Interaktion mit pclass\n",")\n","\n","print(\"üí° Interpretation:\")\n","print(\"   - X-Achse: Feature-Wert (0=male, 1=female)\")\n","print(\"   - Y-Achse: SHAP-Wert (Einfluss auf √úberlebenschance)\")\n","print(\"   - Farbe: Interaktion mit pclass (Passagierklasse)\")"],"metadata":{"id":"fTtmEfIdhoi7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üå≤ RandomForest Feature Importance\n","</font></p>\n","\n","**Konzept**: Zeigt, wie oft und wie stark jedes Feature zur Entscheidungsfindung beitr√§gt."],"metadata":{"id":"90FQMlxFhoi8"}},{"cell_type":"code","source":["# Feature Importance aus RandomForest extrahieren\n","feature_importance = DataFrame({\n","    'Feature': data_train.columns,\n","    'Importance': model.feature_importances_\n","}).sort_values('Importance', ascending=False)\n","\n","# Visualisierung\n","fig = px.bar(\n","    feature_importance,\n","    x='Importance',\n","    y='Feature',\n","    orientation='h',\n","    title='RandomForest Feature Importance (Global)',\n","    labels={'Importance': 'Wichtigkeit', 'Feature': 'Feature'},\n","    color='Importance',\n","    color_continuous_scale='viridis'\n",")\n","fig.update_layout(height=400)\n","fig.show()\n","\n","print(\"\\nüìä Feature Importance Ranking:\")\n","for idx, row in feature_importance.iterrows():\n","    print(f\"  {row['Feature']:10s}: {row['Importance']:.4f}\")"],"metadata":{"id":"erssnFhJml5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# F | Ceteris Paribus Analysen üåç\n","---\n","\n","**Ceteris Paribus** = \"unter sonst gleichen Bedingungen\" (lateinisch)\n","\n","### Was ist eine Ceteris Paribus Analyse?\n","\n","Eine Ceteris Paribus Analyse beantwortet die Frage: **\"Was passiert mit der Vorhersage, wenn ich NUR ein Feature √§ndere?\"**\n","\n","Alle anderen Features bleiben dabei konstant ‚Äì daher der Name.\n","\n","### Beispiel\n","\n","F√ºr Jack (m√§nnlich, 23 Jahre, 3. Klasse) fragen wir:\n","- Was w√§re, wenn Jack in der **1. Klasse** gewesen w√§re? (alle anderen Werte bleiben gleich)\n","- Was w√§re, wenn Jack **50 Jahre** alt gewesen w√§re?\n","\n","### Warum ist das n√ºtzlich?\n","\n","- üéØ Zeigt den **isolierten Einfluss** einzelner Features\n","- üìä Erm√∂glicht **\"Was-w√§re-wenn\"**-Szenarien\n","- üí° Hilft zu verstehen, **wie das Modell \"denkt\"**\n","\n","### Unterschied zu anderen XAI-Methoden\n","\n","| Methode | Frage |\n","|---------|-------|\n","| **SHAP/LIME** | Welche Features haben diese Vorhersage beeinflusst? |\n","| **Ceteris Paribus** | Wie √§ndert sich die Vorhersage, wenn ich ein Feature variiere? |"],"metadata":{"id":"0ZPSqJ-xtUpW"}},{"cell_type":"markdown","source":["\n","**Erkenntnisse:**\n","1. **Alter**: J√ºngere Personen hatten tendenziell h√∂here √úberlebenschancen (\"Women and children first\")\n","2. **Passagierklasse**: 1. Klasse hatte deutlich h√∂here √úberlebenschancen\n","3. **Geschlecht dominiert**: Selbst Jack in 1. Klasse h√§tte schlechtere Chancen als Rose in 3. Klasse!\n"],"metadata":{"id":"wlB1wF5Xml5t"}},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üé® Individual Ceteris Paribus: Jack\n","</font></p>\n","\n","**Was w√§re wenn**: Jack in verschiedenen Passagierklassen gereist w√§re?"],"metadata":{"id":"O-Sj4ItPml5u"}},{"cell_type":"code","source":["# Ceteris Paribus f√ºr Jack: Was passiert in verschiedenen Klassen?\n","jack_cp = jack.copy()\n","\n","pclass_original = [1, 2, 3]\n","jack_predictions = []\n","\n","for pclass in pclass_original:\n","    jack_cp['pclass'] = pclass\n","    pred = model.predict_proba(jack_cp)[0][1] * 100\n","    jack_predictions.append(pred)\n","\n","# Visualisierung\n","fig = px.bar(\n","    x=['1. Klasse', '2. Klasse', '3. Klasse (Jack)'],\n","    y=jack_predictions,\n","    labels={'x': 'Passagierklasse', 'y': '√úberlebenschance (%)'},\n","    title='Ceteris Paribus: Jack - Einfluss der Passagierklasse',\n","    color=jack_predictions,\n","    color_continuous_scale='RdYlGn'\n",")\n","fig.show()\n","\n","print(\"üí° Interpretation:\")\n","print(f\"   Jack in 1. Klasse: {jack_predictions[0]:.2f}%\")\n","print(f\"   Jack in 2. Klasse: {jack_predictions[1]:.2f}%\")\n","print(f\"   Jack in 3. Klasse: {jack_predictions[2]:.2f}% (aktuell)\")\n","print(\"\\n   ‚ö†Ô∏è Selbst in 1. Klasse w√ºrde Jack's m√§nnliches Geschlecht seine Chancen stark begrenzen!\")"],"metadata":{"id":"pdHvniUzml5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<p><font color='black' size=\"5\">\n","üë∞ Individual Ceteris Paribus: Rose\n","</font></p>\n","\n","**Was w√§re wenn**:  Was passiert, wenn wir ihr Alter variieren??"],"metadata":{"id":"JTejWMyhs3KJ"}},{"cell_type":"code","source":["# Ceteris Paribus f√ºr Rose: Was passiert, wenn wir ihr Alter variieren?\n","# Alle anderen Features bleiben konstant\n","\n","age_range = range(0, 80,1)  # Skalierte Werte (StandardScaler)\n","rose_cp = rose.copy()\n","\n","predictions = []\n","for age_val in age_range:\n","    rose_cp['age'] = age_val\n","    pred = model.predict_proba(rose_cp)[0][1] * 100\n","    predictions.append(pred)\n","\n","# Visualisierung\n","fig = px.line(\n","    x=age_range,\n","    y=predictions,\n","    labels={'x': 'Alter', 'y': '√úberlebenschance (%)'},\n","    title='Ceteris Paribus: Rose - Einfluss des Alters'\n",")\n","fig.add_vline(x=rose.iloc[0]['age'], line_dash=\"dash\", line_color=\"red\",\n","              annotation_text=\"Rose aktuell\")\n","fig.show()\n","\n","print(f\"üí° Rose's aktuelles Alter (skaliert): {rose.iloc[0]['age']:.2f}\")\n","print(f\"   Aktuelle √úberlebenschance: {rose_pred:.2f}%\")\n","print(f\"   Interpretation: Je j√ºnger Rose, desto h√∂her ihre √úberlebenschance\")"],"metadata":{"id":"JQ0-D83Nml5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# G | Zusammenfassung üî¨\n","---\n","\n"],"metadata":{"id":"ipRX2qFnlkdM"}},{"cell_type":"markdown","source":["\n","\n","| Framework | üéØ St√§rken | ‚ö†Ô∏è Schw√§chen | üë®‚Äçüéì Einsteigerfreundlichkeit |\n","|-----------|-----------|-------------|---------------------------|\n","| **LIME** | - Sehr intuitives Konzept<br>- Gute visuelle Darstellung<br>- Schnell f√ºr lokale Erkl√§rungen | - Nur lokale Erkl√§rungen<br>- Kann instabil sein | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n","| **SHAP** | - Theoretisch fundiert<br>- Beste Visualisierungen<br>- Lokal & global | - Kann langsam sein<br>- Komplexeres Konzept | ‚≠ê‚≠ê‚≠ê‚≠ê |\n","| **ELI5** | - Extrem einfach<br>- Minimaler Code<br>- Schnell | - Weniger Visualisierungen<br>- Weniger Features | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n","| **InterpretML** | - Interaktive Dashboards<br>- Umfassend<br>- Professionell | - Komplexer Setup<br>- Overhead f√ºr einfache Aufgaben | ‚≠ê‚≠ê‚≠ê |\n","| **RF Importance** | - Extrem schnell<br>- In sklearn integriert<br>- Sehr einfach | - Nur Feature Importance<br>- Keine Richtung des Einflusses | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |"],"metadata":{"id":"YV5Z7KFKt1pn"}},{"cell_type":"markdown","metadata":{"id":"bVfbN5u4Um48"},"source":["**üîó Weiterf√ºhrende Ressourcen**"]},{"cell_type":"markdown","source":["\n","\n","**LIME:**\n","- Dokumentation: https://github.com/marcotcr/lime\n","- Paper: \"Why Should I Trust You?\" (Ribeiro et al., 2016)\n","\n","**SHAP:**\n","- Dokumentation: https://shap.readthedocs.io/\n","- Paper: \"A Unified Approach to Interpreting Model Predictions\" (Lundberg & Lee, 2017)\n","\n","**ELI5:**\n","- Dokumentation: https://eli5.readthedocs.io/\n","\n","**InterpretML:**\n","- Dokumentation: https://interpret.ml/\n","- Microsoft Research: https://www.microsoft.com/en-us/research/project/interpretml/"],"metadata":{"id":"BEOSArOguOgT"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[{"file_id":"1z5m6unJazYZ8KRjYie9oB72ouMbyNlST","timestamp":1768054841552}],"toc_visible":true,"collapsed_sections":["yztPphbhUm4n","uUX9NoXDUm4o","W9kLafCVUm4q","M4KR7HM7Um4r","GVxyDGMWUm4s","hY315AkLUm4s","SQfX_4PoUm4s","95Ky-ds8Um4t","LqLR7CT_Um46","J45xXngSUm47","UOftpSlthoi8","0ZPSqJ-xtUpW","ipRX2qFnlkdM"]}},"nbformat":4,"nbformat_minor":0}