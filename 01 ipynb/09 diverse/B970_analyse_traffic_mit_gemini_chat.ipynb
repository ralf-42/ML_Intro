{"cells":[{"cell_type":"markdown","metadata":{"id":"fd913b05"},"source":["<p><font size=\"6\" color='grey'> <b>\n","Machine Learning\n","</b></font> </br></p>\n","<p><font size=\"5\" color='grey'> <b>\n","Analyse Data with Gemini Chat\n","</b></font> </br></p>\n","\n","---\n"]},{"cell_type":"code","source":["#@title üîß Colab-Umgebung { display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/Python_Modules\n","from ml_lib.utilities import get_ipinfo\n","import sys\n","print()\n","print(f\"Python Version: {sys.version}\")\n","print()\n","get_ipinfo()"],"metadata":{"id":"6RbI__44kP1P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1 | Metro Interstate Traffic Volume\n","---"],"metadata":{"id":"NsRjQsX__7R8"}},{"cell_type":"markdown","source":["St√ºndliches Verkehrsaufkommen auf der Interstate 94 in westlicher Richtung f√ºr die DOT-ATR-Station 301 in Minneapolis und St. Paul, Minnesota, etwa auf halbem Weg zwischen Minneapolis und St. Paul, MN. St√ºndliche Wetterfunktionen und Feiertage f√ºr Auswirkungen auf das Verkehrsaufkommen enthalten.\n","\n","**Datensatz:**\n","\n","+ holiday (Kategorische US-amerikanische Feiertage plus regionaler Feiertag, Minnesota State Fair)\n","+ temp (Numerisch): Durchschnittstemperatur in Kelvin\n","+ rain_1h (Numerisch): Regenmenge in mm pro Stunde\n","+ snow_1h (Numerisch): Schneemenge in mm pro Stunde\n","+ clouds_all (Numerisch): Prozentuale Bew√∂lkung\n","+ weather_main (Kategorische kurze Textbeschreibung des aktuellen Wetters)\n","+ weather_description (Kategorische l√§ngere Textbeschreibung des aktuellen Wetters)\n","+ date_time (Datum/Uhrzeit) Uhrzeit der Datenerfassung (Ortszeit CST)\n","+ traffic_volume (Numerisch): St√ºndliches Verkehrsaufkommen der I-94 ATR 301 in Richtung Westen"],"metadata":{"id":"VhcdTuteBuu9"}},{"cell_type":"markdown","source":["**Citation**     \n","To use these datasets, please cite the papers:\n","Liang Zhao, Olga Gkountouna, and Dieter Pfoser. 2019. Spatial Auto-regressive Dependency Interpretable Learning Based on Spatial Topological Constraints. ACM Trans. Spatial Algorithms Syst. 5, 3, Article 19 (August 2019), 28 pages. DOI:https://doi.org/10.1145/3339823\n"],"metadata":{"id":"6fv8H0ABHsTf"}},{"cell_type":"markdown","source":["Quelle: [UCI](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)"],"metadata":{"id":"4W8E_UgI_9NI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIYdn1woOS1n"},"outputs":[],"source":["!uv pip install --system -q ucimlrepo"]},{"cell_type":"code","source":["from ucimlrepo import fetch_ucirepo\n","\n","# fetch dataset\n","metro_interstate_traffic_volume = fetch_ucirepo(id=492)\n","\n","# data (as pandas dataframes)\n","data = metro_interstate_traffic_volume.data.features\n","target = metro_interstate_traffic_volume.data.targets\n","\n","# metadata\n","print(metro_interstate_traffic_volume.metadata)\n","\n","# variable information\n","print(metro_interstate_traffic_volume.variables)"],"metadata":{"id":"BHL9Ru3m8VyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.holiday.unique()"],"metadata":{"id":"xfVj9Z63hP64"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2 | Modellbildung mit Gemini\n","---"],"metadata":{"id":"yFWfqbRwAXEX"}},{"cell_type":"markdown","metadata":{"id":"202feb12"},"source":["# Task\n","Analysiere die Daten in \"Metro_Interstate_Traffic_Volume.csv\"."]},{"cell_type":"markdown","metadata":{"id":"51551b2c"},"source":["## Datenvorbereitung\n","\n","### Subtask:\n","Bereinigen Sie die Daten, behandeln Sie fehlende Werte und wandeln Sie die Datums-/Zeitspalte in das richtige Format um.\n"]},{"cell_type":"markdown","metadata":{"id":"1ee174b5"},"source":["**Reasoning**:\n","Check the data types and identify missing values in the `data` DataFrame, and fill the missing 'holiday' values with 'None'.\n","\n"]},{"cell_type":"code","metadata":{"id":"f7c089eb"},"source":["print(data.info())\n","data['holiday'] = data['holiday'].fillna('None')\n","display(data.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dcc3fc16"},"source":["**Reasoning**:\n","Import pandas and convert the 'date_time' column to datetime format.\n","\n"]},{"cell_type":"code","metadata":{"id":"AKWsEc1-iGyx"},"source":["import pandas as pd\n","data['date_time'] = pd.to_datetime(data['date_time'])\n","display(data.info())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6143cccf"},"source":["## Explorative datenanalyse (eda)\n","\n","### Subtask:\n","F√ºhren Sie eine erste Untersuchung der Daten durch, um Muster, Trends und Beziehungen zwischen den Variablen zu verstehen. Dazu geh√∂ren die Visualisierung der Verteilung des Verkehrsaufkommens, die Untersuchung des Einflusses von Wetterbedingungen und Feiertagen auf das Verkehrsaufkommen sowie die Analyse zeitbasierter Muster.\n"]},{"cell_type":"markdown","metadata":{"id":"77e6875f"},"source":["**Reasoning**:\n","Import the necessary libraries for visualization and create a histogram of the traffic volume to understand its distribution.\n","\n"]},{"cell_type":"code","metadata":{"id":"971d4d3b"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(10, 6))\n","sns.histplot(target['traffic_volume'], kde=True, bins=50)\n","plt.title('Distribution of Traffic Volume')\n","plt.xlabel('Traffic Volume')\n","plt.ylabel('Frequency')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32f638ee"},"source":["**Reasoning**:\n","Examine the influence of weather conditions and holidays on traffic volume by creating boxplots and bar plots.\n","\n"]},{"cell_type":"code","metadata":{"id":"e6329d88"},"source":["plt.figure(figsize=(14, 7))\n","sns.boxplot(x='weather_main', y=target['traffic_volume'], data=data)\n","plt.title('Traffic Volume by Weather Condition')\n","plt.xlabel('Weather Condition')\n","plt.ylabel('Traffic Volume')\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()\n","\n","plt.figure(figsize=(14, 7))\n","sns.barplot(x='holiday', y=target['traffic_volume'], data=data.replace({'holiday': {None: 'None'}})) # Replace None with 'None' for plotting\n","plt.title('Average Traffic Volume by Holiday')\n","plt.xlabel('Holiday')\n","plt.ylabel('Average Traffic Volume')\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1bbd1e81"},"source":["**Reasoning**:\n","Analyze time-based patterns by plotting traffic volume over time, and then summarize the findings.\n","\n"]},{"cell_type":"code","metadata":{"id":"fcb2030a"},"source":["data_with_target = data.copy()\n","data_with_target['traffic_volume'] = target['traffic_volume']\n","\n","plt.figure(figsize=(15, 6))\n","sns.lineplot(x='date_time', y='traffic_volume', data=data_with_target)\n","plt.title('Traffic Volume Over Time')\n","plt.xlabel('Date and Time')\n","plt.ylabel('Traffic Volume')\n","plt.show()\n","\n","data_with_target['hour'] = data_with_target['date_time'].dt.hour\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(x='hour', y='traffic_volume', data=data_with_target)\n","plt.title('Traffic Volume by Hour of Day')\n","plt.xlabel('Hour of Day')\n","plt.ylabel('Traffic Volume')\n","plt.show()\n","\n","data_with_target['dayofweek'] = data_with_target['date_time'].dt.dayofweek\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(x='dayofweek', y='traffic_volume', data=data_with_target)\n","plt.title('Traffic Volume by Day of Week')\n","plt.xlabel('Day of Week (0=Monday, 6=Sunday)')\n","plt.ylabel('Traffic Volume')\n","plt.show()\n","\n","data_with_target['month'] = data_with_target['date_time'].dt.month\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(x='month', y='traffic_volume', data=data_with_target)\n","plt.title('Traffic Volume by Month')\n","plt.xlabel('Month')\n","plt.ylabel('Traffic Volume')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7d213f87"},"source":["## Feature engineering\n","\n","### Subtask:\n","Erstellen Sie neue Features aus vorhandenen Daten, die die Modellleistung verbessern k√∂nnten. Zum Beispiel k√∂nnen Sie Features f√ºr Stunde, Wochentag, Monat und Jahr aus der Datums-/Zeitspalte extrahieren.\n"]},{"cell_type":"markdown","metadata":{"id":"219a81e5"},"source":["**Reasoning**:\n","Extract hour, day of week, month, and year from the `date_time` column and create new columns in the `data_with_target` DataFrame.\n","\n"]},{"cell_type":"code","metadata":{"id":"3df7ef8d"},"source":["data_with_target['hour'] = data_with_target['date_time'].dt.hour\n","data_with_target['dayofweek'] = data_with_target['date_time'].dt.dayofweek\n","data_with_target['month'] = data_with_target['date_time'].dt.month\n","data_with_target['year'] = data_with_target['date_time'].dt.year\n","display(data_with_target.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bd859506"},"source":["## Modellauswahl\n","\n","### Subtask:\n","W√§hlen Sie geeignete Modelle f√ºr die Vorhersage des Verkehrsaufkommens.\n"]},{"cell_type":"markdown","metadata":{"id":"9dd147d5"},"source":["**Reasoning**:\n","Select appropriate regression models based on the insights from EDA and feature engineering, considering models that can capture seasonal patterns, the impact of holidays and weather conditions, and temporal dependencies. Briefly justify the choice of models based on their strengths and suitability for the task at hand.\n","\n"]},{"cell_type":"code","metadata":{"id":"f522af98"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","import numpy as np\n","\n","# Separate features and target\n","X = data_with_target.drop(['traffic_volume', 'date_time'], axis=1)\n","y = data_with_target['traffic_volume']\n","\n","# Identify categorical and numerical features\n","categorical_features = ['holiday', 'weather_main', 'weather_description']\n","numerical_features = ['temp', 'rain_1h', 'snow_1h', 'clouds_all', 'hour', 'dayofweek', 'month', 'year']\n","\n","# Create a column transformer for one-hot encoding categorical features\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', 'passthrough', numerical_features),\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n","\n","# Create a RandomForestRegressor model\n","rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n","\n","# Create a pipeline that first preprocesses the data and then trains the model\n","pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                           ('regressor', rf_model)])\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train the model\n","pipeline.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = pipeline.predict(X_test)\n","\n","# Evaluate the model\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f'Mean Squared Error: {mse}')\n","print(f'Root Mean Squared Error: {rmse}')\n","print(f'R-squared: {r2}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0b4ce1c2"},"source":["# Get feature importances from the trained model\n","feature_importances = pipeline.named_steps['regressor'].feature_importances_\n","\n","# Get the feature names after one-hot encoding\n","# The get_feature_names_out() method is available from scikit-learn version 1.0\n","try:\n","    feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n","except AttributeError:\n","    # Fallback for older versions of scikit-learn\n","    # This might not be perfect as it doesn't handle unknown categories explicitly\n","    ohe_feature_names = pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features)\n","    feature_names = numerical_features + list(ohe_feature_names)\n","\n","\n","# Create a pandas Series for better visualization\n","feature_importances_series = pd.Series(feature_importances, index=feature_names)\n","\n","# Sort feature importances in descending order\n","sorted_feature_importances = feature_importances_series.sort_values(ascending=False)\n","\n","# Print the top 10 most important features\n","print(\"Top 10 Most Important Features:\")\n","print(sorted_feature_importances.head(10))\n","\n","# Visualize feature importances\n","plt.figure(figsize=(12, 8))\n","sorted_feature_importances.head(20).plot(kind='barh')\n","plt.title('Top 20 Feature Importances')\n","plt.xlabel('Importance')\n","plt.ylabel('Feature')\n","plt.gca().invert_yaxis()  # Display the most important feature at the top\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3f35e056"},"source":["# Task\n","Analysiere die Daten und erstelle ein RandomForest Modell zur Vorhersage von Staus."]},{"cell_type":"markdown","metadata":{"id":"2665cf21"},"source":["## Definition von stau\n","\n","### Subtask:\n","Definieren Sie, was in diesem Datensatz als \"Stau\" betrachtet werden soll. Dies k√∂nnte auf einem Schwellenwert f√ºr das Verkehrsaufkommen oder anderen verf√ºgbaren Informationen basieren.\n"]},{"cell_type":"markdown","metadata":{"id":"90b41c7d"},"source":["**Reasoning**:\n","Analyze the distribution of traffic volume to determine a suitable threshold for defining \"Stau\".\n","\n"]},{"cell_type":"code","metadata":{"id":"15fe90e9"},"source":["display(data_with_target['traffic_volume'].describe())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7139d15"},"source":["**Reasoning**:\n","Based on the distribution of the traffic volume, a threshold needs to be defined. The descriptive statistics show the mean, median, and quartiles. A value above the 75th percentile (4933) seems reasonable to consider as \"Stau\" or congestion, as it represents the upper quartile of traffic volume.\n","\n"]},{"cell_type":"code","metadata":{"id":"24d9925c"},"source":["stau_threshold = 5000\n","print(f\"We define 'Stau' (congestion) as a traffic volume greater than {stau_threshold}.\")\n","print(\"This threshold was chosen because it is slightly above the 75th percentile of the traffic volume distribution, representing the upper quartile of observed traffic.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af5fc74d"},"source":["## Datenvorbereitung f√ºr stau-klassifizierung\n","\n","### Subtask:\n","Erstellen Sie ein neues Ziel-Feature, das angibt, ob ein Stau vorliegt oder nicht, basierend auf der in Schritt 1 definierten Regel. Behandeln Sie die Daten entsprechend f√ºr eine Klassifizierungsaufgabe.\n"]},{"cell_type":"markdown","metadata":{"id":"e51ba368"},"source":["**Reasoning**:\n","Create a new binary column 'is_stau' based on the 'traffic_volume' and 'stau_threshold', and then display the head and value counts of the updated dataframe to verify the new column and its distribution.\n","\n"]},{"cell_type":"code","metadata":{"id":"25447bb3"},"source":["data_with_target['is_stau'] = (data_with_target['traffic_volume'] > stau_threshold).astype(int)\n","display(data_with_target.head())\n","display(data_with_target['is_stau'].value_counts())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ea26bcf9"},"source":["## Feature engineering (falls erforderlich)\n","\n","### Subtask:\n","√úberpr√ºfen Sie die vorhandenen Features und erstellen Sie gegebenenfalls neue, die f√ºr die Stauvorhersage relevant sein k√∂nnten.\n"]},{"cell_type":"markdown","metadata":{"id":"1ec213a2"},"source":["## Modellauswahl f√ºr klassifizierung\n","\n","### Subtask:\n","W√§hlen Sie geeignete Klassifizierungsmodelle f√ºr die Vorhersage von Staus.\n"]},{"cell_type":"markdown","metadata":{"id":"24c4cece"},"source":["**Reasoning**:\n","Select two classification models suitable for binary classification, considering the dataset characteristics and the class imbalance. Justify the choices and briefly mention how to handle class imbalance.\n","\n"]},{"cell_type":"code","metadata":{"id":"08ace482"},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","\n","print(\"Selected Classification Models:\")\n","print(\"1. Logistic Regression: A simple yet effective model for binary classification. It provides interpretable coefficients and can serve as a good baseline. While it assumes linearity, it can still perform reasonably well on complex data.\")\n","print(\"2. RandomForestClassifier: An ensemble method that can capture non-linear relationships and is generally robust to outliers. It's known for its good performance and provides feature importances, which can be useful for understanding the factors influencing traffic congestion.\")\n","\n","print(\"\\nAddressing Class Imbalance:\")\n","print(\"The observed class imbalance (more 'no congestion' than 'congestion') can be handled during modeling by:\")\n","print(\"- Adjusting class weights in the model training to give more importance to the minority class ('congestion').\")\n","print(\"- Using appropriate evaluation metrics beyond accuracy, such as precision, recall, F1-score, and AUC-ROC, which are less sensitive to class distribution.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b8a7465e"},"source":["## Modelltraining f√ºr klassifizierung\n","\n","### Subtask:\n","Trainieren Sie die ausgew√§hlten Klassifizierungsmodelle.\n"]},{"cell_type":"markdown","metadata":{"id":"0c40e2ad"},"source":["**Reasoning**:\n","Separate features and target, identify categorical and numerical features, create a column transformer for one-hot encoding, instantiate a RandomForestClassifier with balanced class weights, create a pipeline, and split the data into training and testing sets.\n","\n"]},{"cell_type":"code","metadata":{"id":"afe9bfea"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Separate features and the new target variable 'is_stau'\n","X = data_with_target.drop(['traffic_volume', 'date_time', 'is_stau'], axis=1)\n","y = data_with_target['is_stau']\n","\n","# Identify categorical and numerical features\n","categorical_features = ['holiday', 'weather_main', 'weather_description']\n","numerical_features = ['temp', 'rain_1h', 'snow_1h', 'clouds_all', 'hour', 'dayofweek', 'month', 'year']\n","\n","# Create a column transformer for one-hot encoding categorical features\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', 'passthrough', numerical_features),\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n","\n","# Instantiate a RandomForestClassifier model with balanced class weights\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')\n","\n","# Create a pipeline that first preprocesses the data and then trains the model\n","pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                           ('classifier', rf_model)])\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train the model\n","pipeline.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2e87e884"},"source":["## Modellevaluierung f√ºr klassifizierung\n","\n","### Subtask:\n","Bewerten Sie die Leistung der trainierten Klassifizierungsmodelle anhand geeigneter Metriken (z. B. Genauigkeit, Pr√§zision, Recall, F1-Score).\n"]},{"cell_type":"markdown","metadata":{"id":"f5e2b253"},"source":["**Reasoning**:\n","Evaluate the performance of the trained classification model using accuracy, precision, recall, F1-score, and AUC-ROC.\n","\n"]},{"cell_type":"code","metadata":{"id":"c25bf1ef"},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","# Make predictions\n","y_pred = pipeline.predict(X_test)\n","y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","roc_auc = roc_auc_score(y_test, y_pred_proba)\n","\n","# Print the metrics\n","print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","print(f'F1-Score: {f1}')\n","print(f'AUC-ROC: {roc_auc}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2d78932a"},"source":["## Ergebnisse interpretieren\n","\n","### Subtask:\n","Analysieren Sie die Ergebnisse der Modelle, um die wichtigsten Faktoren zu identifizieren, die mit Staus korrelieren.\n"]},{"cell_type":"markdown","metadata":{"id":"b352937f"},"source":["**Reasoning**:\n","Access and visualize the feature importances from the trained RandomForestClassifier model to identify the most influential factors in predicting traffic congestion.\n","\n"]},{"cell_type":"code","metadata":{"id":"8fe7de50"},"source":["# Access the trained RandomForestClassifier model from the pipeline\n","rf_classifier_model = pipeline.named_steps['classifier']\n","\n","# Get feature importances\n","feature_importances = rf_classifier_model.feature_importances_\n","\n","# Get the feature names after one-hot encoding\n","try:\n","    feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n","except AttributeError:\n","    # Fallback for older versions of scikit-learn\n","    # This might not be perfect as it doesn't handle unknown categories explicitly\n","    ohe_feature_names = pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features)\n","    feature_names = numerical_features + list(ohe_feature_names)\n","\n","# Create a pandas Series for better visualization\n","feature_importances_series = pd.Series(feature_importances, index=feature_names)\n","\n","# Sort feature importances in descending order\n","sorted_feature_importances = feature_importances_series.sort_values(ascending=False)\n","\n","# Print the top 10 most important features\n","print(\"Top 10 Most Important Features:\")\n","print(sorted_feature_importances.head(10))\n","\n","# Visualize feature importances\n","plt.figure(figsize=(12, 8))\n","sorted_feature_importances.head(20).plot(kind='barh')\n","plt.title('Top 20 Feature Importances for Traffic Congestion Prediction')\n","plt.xlabel('Importance')\n","plt.ylabel('Feature')\n","plt.gca().invert_yaxis()  # Display the most important feature at the top\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10856926"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   Traffic congestion (\"Stau\") was defined as a traffic volume greater than 5000, which is slightly above the 75th percentile of the observed traffic volume distribution.\n","*   The dataset exhibits class imbalance, with significantly more instances of no traffic congestion (0) than congestion (1).\n","*   Two classification models, Logistic Regression (as a baseline) and RandomForestClassifier, were selected as suitable for the task.\n","*   A RandomForestClassifier model was trained using a pipeline that included one-hot encoding for categorical features and used balanced class weights to address the data imbalance.\n","*   The trained RandomForest model achieved an Accuracy of 0.9388, Precision of 0.8785, Recall of 0.8592, F1-Score of 0.8687, and an AUC-ROC of 0.9800 on the test set.\n","*   The most important features identified by the RandomForest model for predicting traffic congestion are time-based: the hour of the day ('hour') and the day of the week ('dayofweek').\n","*   Temperature ('temp') is also a significant predictor, following the time-based features in importance.\n","\n","### Insights or Next Steps\n","\n","*   The high importance of time-based features suggests that traffic congestion is strongly driven by daily and weekly patterns, likely reflecting commuter behavior and peak hours. Further analysis could focus on specific times of day and days of the week to understand congestion patterns in more detail.\n","*   Given the strong predictive power of time and temperature, future modeling efforts could explore interaction terms between these features or investigate non-linear relationships to potentially improve performance further.\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/empty.ipynb","timestamp":1750954269898}],"toc_visible":true,"collapsed_sections":["NsRjQsX__7R8","yFWfqbRwAXEX","202feb12","51551b2c","6143cccf","7d213f87","bd859506","3f35e056","2665cf21","af5fc74d","ea26bcf9","1ec213a2","b8a7465e","2e87e884","2d78932a","10856926"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}