{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["6efPloEbBKvY","gRLAaL1vBMvV","05b5d99b","904401c5","3f27bd91","2aa36de1","fb63dfaa","c060a7e4","b2664cbe","17bf8f7c","57dbb1ec","bc191359","305a3970","06117a95","c572a882","ff7ef7c1"],"authorship_tag":"ABX9TyNVHU/6kdF5EeGmrfCBeoM4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fd913b05"},"source":["<p><font size=\"6\" color='grey'> <b>\n","Machine Learning\n","</b></font> </br></p>\n","<p><font size=\"5\" color='grey'> <b>\n","Analyse Data with Gemini Chat\n","</b></font> </br></p>\n","\n","---\n"]},{"cell_type":"code","source":["#@title üîß Colab-Umgebung { display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/Python_Modules\n","from ml_lib.utilities import get_ipinfo\n","import sys\n","print()\n","print(f\"Python Version: {sys.version}\")\n","print()\n","get_ipinfo()"],"metadata":{"id":"BTHNUQSWj5Fk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1 | Analyse Kreditw√ºrdigkeit"],"metadata":{"id":"6efPloEbBKvY"}},{"cell_type":"markdown","source":["**Erl√§uterung zu den Daten in credit.csv:**\n","\n","Dieser Datensatz enth√§lt einen vereinfachten Ausschnitt an Informationen zu 1000 Kreditantr√§gen und deren Bonit√§t in Deutschland. Er wird h√§ufig f√ºr die Entwicklung und Bewertung von Kreditrisikomodellen verwendet. Hier ist eine kurze Beschreibung der verwendeten Datenfelder:\n","\n","+ credit_duration_months: Die Laufzeit des Kredits in Monaten.\n","+ credit_amount_eur: Der beantragte Kreditbetrag in Euro.\n","+ installment_rate: Die Rate, zu der der Kredit in Prozent des verf√ºgbaren Einkommens zur√ºckgezahlt werden soll.\n","+ age_years: Das Alter des Kreditnehmers in Jahren.\n","+ num_existing_credits: Die Anzahl der bestehenden Kredite, die der Kreditnehmer bereits hat.\n","+ credit_purpose: Der Verwendungszweck des Kredits (z.B. Autokauf, M√∂bel, Gesch√§ft usw.).\n","+ credit_risk: Die Bonit√§t des Kreditnehmers, in der Regel als 0 (hohes Risiko/schlechter Kunde) oder 1 (geringes Risiko/guter Kunde) kodiert.   \n","\n","\n","Quelle: [UCI](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)"],"metadata":{"id":"PBxWsobixc4p"}},{"cell_type":"markdown","source":["# 2 | Modellbildung mit Gemini\n","---"],"metadata":{"id":"gRLAaL1vBMvV"}},{"cell_type":"markdown","metadata":{"id":"05b5d99b"},"source":["# Task\n","Analysiere die Daten in \"credit.csv\"."]},{"cell_type":"markdown","metadata":{"id":"904401c5"},"source":["## Load the data\n","\n","### Subtask:\n","Load the data from the `credit.csv` file into a pandas DataFrame.\n"]},{"cell_type":"markdown","metadata":{"id":"88e36002"},"source":["**Reasoning**:\n","Import the pandas library and load the data into a pandas DataFrame.\n","\n"]},{"cell_type":"code","metadata":{"id":"0981c3cd"},"source":["import pandas as pd\n","\n","df = pd.read_csv('https://raw.githubusercontent.com/ralf-42/ML_Intro/main/02%20data/credit.csv')\n","display(df.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3f27bd91"},"source":["## Explore the data\n","\n","### Subtask:\n","Display the first few rows, check the data types, and look for missing values.\n"]},{"cell_type":"markdown","metadata":{"id":"32af9830"},"source":["**Reasoning**:\n","Display the first few rows, check data types, and look for missing values in the dataframe as instructed.\n","\n"]},{"cell_type":"code","metadata":{"id":"fc4eb507"},"source":["display(df.head())\n","display(df.info())\n","display(df.isnull().sum())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2aa36de1"},"source":["## Analyze the data\n","\n","### Subtask:\n","Perform some basic analysis on the data, such as calculating descriptive statistics and visualizing the distributions of key features.\n"]},{"cell_type":"markdown","metadata":{"id":"f2b14bf8"},"source":["**Reasoning**:\n","Calculate and display descriptive statistics for the numerical columns.\n","\n"]},{"cell_type":"code","metadata":{"id":"d51ef662"},"source":["display(df.describe())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"69ae1c5a"},"source":["**Reasoning**:\n","Create histograms for the numerical columns to visualize their distributions.\n","\n"]},{"cell_type":"code","metadata":{"id":"357311b0"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","numerical_cols = ['credit_duration_months', 'credit_amount_eur', 'installment_rate', 'age_years', 'num_existing_credits']\n","df[numerical_cols].hist(figsize=(15, 10), bins=20)\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ef9c2c3"},"source":["**Reasoning**:\n","Create a bar plot for the 'credit_purpose' column to visualize the frequency of each credit purpose category.\n","\n"]},{"cell_type":"code","metadata":{"id":"e6a4ac56"},"source":["plt.figure(figsize=(12, 6))\n","sns.countplot(data=df, y='credit_purpose', order = df['credit_purpose'].value_counts().index)\n","plt.title('Distribution of Credit Purpose')\n","plt.xlabel('Frequency')\n","plt.ylabel('Credit Purpose')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"276697d0"},"source":["**Reasoning**:\n","Create a count plot for the 'credit_risk' column to visualize the distribution of credit risk categories.\n","\n"]},{"cell_type":"code","metadata":{"id":"3f675552"},"source":["plt.figure(figsize=(6, 4))\n","sns.countplot(data=df, x='credit_risk')\n","plt.title('Distribution of Credit Risk')\n","plt.xlabel('Credit Risk')\n","plt.ylabel('Frequency')\n","plt.xticks([0, 1], ['Low Risk (0)', 'High Risk (1)'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fb63dfaa"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   The dataset contains 1000 entries and 7 columns, including numerical features like `credit_duration_months`, `credit_amount_eur`, `installment_rate`, `age_years`, and `num_existing_credits`, and categorical features like `credit_purpose` and `credit_risk`.\n","*   There are no missing values in any of the columns.\n","*   Numerical features such as `credit_duration_months` and `credit_amount_eur` show right-skewed distributions.\n","*   The dataset contains more instances of low-risk credits (labeled 0) than high-risk credits (labeled 1).\n","*   The count plot of `credit_purpose` shows the frequency of each credit purpose category, highlighting which purposes are most common.\n","\n","### Insights or Next Steps\n","\n","*   Investigate the relationships between the numerical features and the `credit_risk` to understand which factors contribute most to credit risk.\n","*   Analyze the distribution of `credit_purpose` in relation to `credit_risk` to see if certain purposes are associated with higher risk.\n"]},{"cell_type":"markdown","metadata":{"id":"c060a7e4"},"source":["# Task\n","Analyze \"credit.csv\", create a classification model with 'credit risk' as the target variable, and evaluate its performance."]},{"cell_type":"markdown","metadata":{"id":"b2664cbe"},"source":["## Prepare the data\n","\n","### Subtask:\n","Preprocess the data by handling categorical variables and splitting the dataset into training and testing sets.\n"]},{"cell_type":"markdown","metadata":{"id":"59684a8f"},"source":["**Reasoning**:\n","Convert the 'credit_purpose' column to numerical using one-hot encoding, separate features and target, and split the data into training and testing sets as instructed.\n","\n"]},{"cell_type":"code","metadata":{"id":"ee757fc7"},"source":["df_encoded = pd.get_dummies(df, columns=['credit_purpose'], drop_first=True)\n","\n","X = df_encoded.drop('credit_risk', axis=1)\n","y = df_encoded['credit_risk']\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","display(X_train.head())\n","display(y_train.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"17bf8f7c"},"source":["## Choose and train a model\n","\n","### Subtask:\n","Select a suitable classification model and train it on the training data.\n"]},{"cell_type":"markdown","metadata":{"id":"97021fc1"},"source":["**Reasoning**:\n","Import the Logistic Regression model and train it on the training data.\n","\n"]},{"cell_type":"code","metadata":{"id":"19cb9c48"},"source":["from sklearn.linear_model import LogisticRegression\n","\n","model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"57dbb1ec"},"source":["## Evaluate the model\n","\n","### Subtask:\n","Evaluate the trained model's performance on the testing data using appropriate metrics.\n"]},{"cell_type":"markdown","metadata":{"id":"6e954caa"},"source":["**Reasoning**:\n","Use the trained model to make predictions on the test set and evaluate the model's performance using various classification metrics.\n","\n"]},{"cell_type":"code","metadata":{"id":"54126bb4"},"source":["y_pred = model.predict(X_test)\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy:.4f}')\n","print(f'Precision: {precision:.4f}')\n","print(f'Recall: {recall:.4f}')\n","print(f'F1 Score: {f1:.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bc191359"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   The 'credit\\_purpose' categorical variable was successfully one-hot encoded.\n","*   The dataset was split into training (80%) and testing (20%) sets.\n","*   A Logistic Regression model was trained on the training data.\n","*   The model achieved an accuracy of 0.7050 on the test set.\n","*   The model showed a high recall of 0.9362, indicating it is good at identifying positive cases.\n","*   The precision of the model was 0.7253, and the F1 Score was 0.8173.\n","\n","### Insights or Next Steps\n","\n","*   Investigate the `ConvergenceWarning` during model training and consider increasing `max_iter` or using feature scaling to potentially improve convergence and model performance.\n","*   Explore other classification models and compare their performance to the Logistic Regression model using cross-validation for a more robust evaluation.\n"]},{"cell_type":"markdown","metadata":{"id":"305a3970"},"source":["# Task\n","Analysiere \"credit.csv\", erstelle ein Klassifizierungsmodell f√ºr 'credit risk' mit Random Forest, erkl√§re 'recall' und bewerte das Modell."]},{"cell_type":"markdown","metadata":{"id":"06117a95"},"source":["## Choose and train a model\n","\n","### Subtask:\n","Select the Random Forest classification model and train it on the training data.\n"]},{"cell_type":"markdown","metadata":{"id":"1c2b479d"},"source":["**Reasoning**:\n","Import the RandomForestClassifier model and train it on the training data as instructed.\n","\n"]},{"cell_type":"code","metadata":{"id":"8441dfb7"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rf_model = RandomForestClassifier(random_state=42)\n","rf_model.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c572a882"},"source":["## Evaluate the model\n","\n","### Subtask:\n","Evaluate the trained Random Forest model's performance on the testing data using appropriate metrics.\n"]},{"cell_type":"markdown","metadata":{"id":"a0525949"},"source":["**Reasoning**:\n","Use the trained Random Forest model to make predictions on the test set and evaluate the model's performance using various classification metrics.\n","\n"]},{"cell_type":"code","metadata":{"id":"d537ae2c"},"source":["y_pred_rf = rf_model.predict(X_test)\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","accuracy_rf = accuracy_score(y_test, y_pred_rf)\n","precision_rf = precision_score(y_test, y_pred_rf)\n","recall_rf = recall_score(y_test, y_pred_rf)\n","f1_rf = f1_score(y_test, y_pred_rf)\n","\n","print(f'Random Forest Accuracy: {accuracy_rf:.4f}')\n","print(f'Random Forest Precision: {precision_rf:.4f}')\n","print(f'Random Forest Recall: {recall_rf:.4f}')\n","print(f'Random Forest F1 Score: {f1_rf:.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ff7ef7c1"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   The Random Forest model achieved an accuracy of approximately 69.50% on the test data.\n","*   The precision of the model was around 74.39%, while the recall was approximately 86.52%.\n","*   The F1-score for the model was 80.00%.\n","\n","### Insights or Next Steps\n","\n","*   The model shows a higher recall than precision, indicating it is better at identifying positive cases (good credit risk) than avoiding false positives.\n","*   Further analysis could involve hyperparameter tuning to potentially improve precision without significantly sacrificing recall, depending on the business objective (minimizing missed good risks vs. minimizing false positives that might deny credit to eligible applicants).\n"]}]}