{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["aGvRZJ9TfQFn","hSqc04L3fNSH","a1w1xV8ZfNSI","6Z3bvFi-fNSK","8jmsV7t1tUVC"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<p><font size=\"6\" color='grey'> <b>\n","Machine Learning\n","</b></font> </br></p>\n","<p><font size=\"5\" color='grey'> <b>\n","Large Language Model - einfacher Chatbot\n","\n","---"],"metadata":{"id":"dC-pFnQoeYWF"}},{"cell_type":"code","source":["#@title üîß Colab-Umgebung { display-mode: \"form\" }\n","!uv pip install --system -q git+https://github.com/ralf-42/Python_Modules\n","from ml_lib.utilities import get_ipinfo\n","import sys\n","print()\n","print(f\"Python Version: {sys.version}\")\n","print()\n","get_ipinfo()"],"metadata":{"id":"U00QIFQriGuL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 0 | Install & Import\n","---"],"metadata":{"id":"aGvRZJ9TfQFn"}},{"cell_type":"code","source":["!uv pip install --system -qU langchain_openai langchain_community openai httpx"],"metadata":{"id":"DJKvwwb3qPGB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title\n","#@markdown   <p><font size=\"4\" color='blue'>  Hinweis bei unerwartetem Fehler</font> </br></p>\n","# Hilfsl√∂sung f√ºr Fehler mit OpenAI 1.56.0 - Client.__init__() hat ein unerwartetes Schl√ºsselwortargument 'proxyes' erhalten\n","# Ende mit Fehler: ERROR: pip's dependency resolver does not currently take into account -- weitere Ausf√ºhrung klappt trotzdem\n","# !pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet\n","# import os\n","# os.kill(os.getpid(), 9)"],"metadata":{"id":"8sWw4u-1rZPP","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","from google.colab import userdata\n","import openai\n","\n","from langchain_openai import ChatOpenAI\n","from langchain.schema import AIMessage, HumanMessage\n","\n","import gradio as gr"],"metadata":{"id":"uYRljY86fimB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hSqc04L3fNSH"},"source":["# 1 | √úbergreifende Parameter\n","---\n","\n"]},{"cell_type":"code","source":["# OpenAI API Schl√ºssel setzen\n","OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"],"metadata":{"id":"apJXV4coqaUv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2 | App-Integration ChatBot\n","---\n","\n"],"metadata":{"id":"a1w1xV8ZfNSI"}},{"cell_type":"code","source":["model = ChatOpenAI(model=\"gpt-4o-mini\")\n","\n","\n","def predict(message, history):\n","    history_langchain_format = []\n","    for msg in history:\n","        if msg[\"role\"] == \"user\":\n","            history_langchain_format.append(HumanMessage(content=msg[\"content\"]))\n","        elif msg[\"role\"] == \"assistant\":\n","            history_langchain_format.append(AIMessage(content=msg[\"content\"]))\n","    history_langchain_format.append(HumanMessage(content=message))\n","    gpt_response = model.invoke(history_langchain_format)\n","    return gpt_response.content"],"metadata":{"id":"nB0O2_ijqXZs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 | App Design\n","---"],"metadata":{"id":"6Z3bvFi-fNSK"}},{"cell_type":"code","source":["demo = gr.ChatInterface(\n","    predict,\n","    type=\"messages\",\n","    title=\"ü§ñ Einfacher ChatBot\",\n",")"],"metadata":{"id":"-xod30RGt0d2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4 | Launch\n","---"],"metadata":{"id":"8jmsV7t1tUVC"}},{"cell_type":"code","source":["demo.launch()"],"metadata":{"id":"b0sA8IWmu64Q"},"execution_count":null,"outputs":[]}]}