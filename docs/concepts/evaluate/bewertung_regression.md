---
layout: default
title: Regression
parent: Evaluate
grand_parent: Konzepte
nav_order: 3
description: "Bewertungsmetriken fÃ¼r Regressionsmodelle: BestimmtheitsmaÃŸ RÂ², Mean Absolute Error und Residuenanalyse"
has_toc: true
---

# Evaluation Regression
{: .no_toc }

> **Regressionsmodelle bewerten die QualitÃ¤t ihrer Vorhersagen durch verschiedene Metriken.**       Das BestimmtheitsmaÃŸ RÂ², der Mean Absolute Error und die Residuenanalyse bilden das Fundament einer soliden Modellbewertung.

---

## Inhaltsverzeichnis
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Ãœbersicht der Regressionsmetriken

Bei der Evaluation von Regressionsmodellen stehen verschiedene Metriken zur VerfÃ¼gung, die unterschiedliche Aspekte der VorhersagequalitÃ¤t beleuchten.

```mermaid
flowchart TD
    subgraph Metriken["ğŸ“Š Regressionsmetriken"]
        R2["RÂ²<br/>BestimmtheitsmaÃŸ"]
        MAE["MAE<br/>Mean Absolute Error"]
        MSE["MSE<br/>Mean Squared Error"]
        RMSE["RMSE<br/>Root Mean Squared Error"]
    end
    
    subgraph Interpretation["ğŸ¯ Was sie messen"]
        R2_INT["ErklÃ¤rte Varianz<br/>0 bis 1"]
        MAE_INT["Durchschnittlicher<br/>absoluter Fehler"]
        MSE_INT["Durchschnittlicher<br/>quadratischer Fehler"]
        RMSE_INT["Fehler in<br/>Originaleinheit"]
    end
    
    R2 --> R2_INT
    MAE --> MAE_INT
    MSE --> MSE_INT
    RMSE --> RMSE_INT
    
    style R2 fill:#4CAF50,color:#fff
    style MAE fill:#2196F3,color:#fff
    style MSE fill:#FF9800,color:#fff
    style RMSE fill:#9C27B0,color:#fff
```

---

## BestimmtheitsmaÃŸ (RÂ²)

Das BestimmtheitsmaÃŸ ist ein statistisches MaÃŸ, das verwendet wird, um den Grad der ErklÃ¤rungskraft eines Modells oder einer Regressionsanalyse zu quantifizieren.

### Konzept

RÂ² misst, wie gut die abhÃ¤ngige Variable durch die unabhÃ¤ngigen Variablen erklÃ¤rt werden kann. Es beantwortet die Frage: **Wie viel der Varianz in den Daten kann das Modell erklÃ¤ren?**

```mermaid
flowchart LR
    subgraph Modell["ğŸ”® Regressionsmodell"]
        X["Features X"]
        Y["Zielvariable y"]
        PRED["Vorhersage Å·"]
    end
    
    subgraph R2_Calc["ğŸ“ RÂ² Berechnung"]
        VAR_TOTAL["Gesamtvarianz<br/>SS_total"]
        VAR_RESIDUAL["Residualvarianz<br/>SS_residual"]
        RESULT["RÂ² = 1 - SS_res/SS_total"]
    end
    
    X --> PRED
    Y --> VAR_TOTAL
    PRED --> VAR_RESIDUAL
    VAR_TOTAL --> RESULT
    VAR_RESIDUAL --> RESULT
    
    style RESULT fill:#4CAF50,color:#fff
```

### Interpretation

| RÂ²-Wert | Interpretation |
|---------|----------------|
| **1.0** | Perfekte ErklÃ¤rung â€“ Modell erklÃ¤rt 100% der Varianz |
| **0.8 - 1.0** | Sehr gute ErklÃ¤rungskraft |
| **0.6 - 0.8** | Gute ErklÃ¤rungskraft |
| **0.4 - 0.6** | Moderate ErklÃ¤rungskraft |
| **0.0 - 0.4** | Schwache ErklÃ¤rungskraft |
| **< 0** | Modell schlechter als Mittelwert-Vorhersage |

{: .warning }
> **Wichtig:** Ein hoher RÂ²-Wert allein garantiert kein gutes Modell. RÂ² sollte immer in Verbindung mit anderen Metriken und einer Residuenanalyse betrachtet werden.

### Mathematische Definition

Die Berechnung erfolgt Ã¼ber das VerhÃ¤ltnis von erklÃ¤rter zu gesamter Varianz:

$$R^2 = 1 - \frac{SS_{residual}}{SS_{total}} = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}$$

Wobei:
- $y_i$ = tatsÃ¤chlicher Wert
- $\hat{y}_i$ = vorhergesagter Wert
- $\bar{y}$ = Mittelwert der tatsÃ¤chlichen Werte

### Implementation in Python

```python
from sklearn.metrics import r2_score
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import numpy as np

# Beispieldaten
data = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
target = np.array([2.1, 4.2, 5.8, 8.1, 10.2, 11.9, 14.1, 16.0, 18.2, 20.1])

# Train-Test-Split
data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=42)

# Modell trainieren
model = LinearRegression()
model.fit(data_train, target_train)

# Vorhersagen
target_pred = model.predict(data_test)

# RÂ² berechnen
r2 = r2_score(target_test, target_pred)
print(f"RÂ² Score: {r2:.4f}")

# RÂ² fÃ¼r Trainings- und Testdaten vergleichen
r2_train = r2_score(target_train, model.predict(data_train))
r2_test = r2_score(target_test, target_pred)

print(f"RÂ² Training: {r2_train:.4f}")
print(f"RÂ² Test:     {r2_test:.4f}")
```

---

## Mean Absolute Error (MAE)

Der Mean Absolute Error ist eine hÃ¤ufig verwendete Metrik zur Bewertung der Genauigkeit von Vorhersagemodellen.

### Konzept

MAE misst den durchschnittlichen absoluten Unterschied zwischen den tatsÃ¤chlichen Werten und den vorhergesagten Werten. Er ist besonders nÃ¼tzlich, wenn AusreiÃŸer in den Daten vorhanden sind, da er weniger empfindlich auf extreme Werte reagiert als andere Metriken.

```mermaid
flowchart TD
    subgraph Berechnung["ğŸ“Š MAE Berechnung"]
        REAL["TatsÃ¤chliche<br/>Werte y"]
        PRED["Vorhergesagte<br/>Werte Å·"]
        DIFF["Differenz<br/>|y - Å·|"]
        ABS["Absolutwerte<br/>bilden"]
        MEAN["Mittelwert<br/>berechnen"]
        MAE["MAE"]
    end
    
    REAL --> DIFF
    PRED --> DIFF
    DIFF --> ABS
    ABS --> MEAN
    MEAN --> MAE
    
    style MAE fill:#2196F3,color:#fff
    style MEAN fill:#64B5F6,color:#fff
```

### Eigenschaften

| Eigenschaft | Beschreibung |
|-------------|--------------|
| **Wertebereich** | 0 bis âˆ (je kleiner, desto besser) |
| **Einheit** | Gleiche Einheit wie Zielvariable |
| **AusreiÃŸer** | Weniger empfindlich als MSE |
| **Interpretierbarkeit** | Leicht verstÃ¤ndlich |

### Mathematische Definition

$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

### Vergleich MAE vs. MSE vs. RMSE

```mermaid
flowchart LR
    subgraph Metriken["Fehlermetriken im Vergleich"]
        MAE_BOX["**MAE**<br/>Mittlerer absoluter Fehler<br/>Robust gegen AusreiÃŸer"]
        MSE_BOX["**MSE**<br/>Mittlerer quadratischer Fehler<br/>Bestraft groÃŸe Fehler stÃ¤rker"]
        RMSE_BOX["**RMSE**<br/>Wurzel des MSE<br/>Gleiche Einheit wie y"]
    end
    
    style MAE_BOX fill:#2196F3,color:#fff
    style MSE_BOX fill:#FF9800,color:#fff
    style RMSE_BOX fill:#9C27B0,color:#fff
```

| Metrik | Formel | Besonderheit |
|--------|--------|--------------|
| **MAE** | $\frac{1}{n}\sum\|y-\hat{y}\|$ | Robust gegen AusreiÃŸer |
| **MSE** | $\frac{1}{n}\sum(y-\hat{y})^2$ | Bestraft groÃŸe Fehler quadratisch |
| **RMSE** | $\sqrt{MSE}$ | Interpretierbar in Originaleinheit |

### Implementation in Python

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

# Beispiel: TatsÃ¤chliche und vorhergesagte Werte
target_true = np.array([3.0, -0.5, 2.0, 7.0, 4.5])
target_pred = np.array([2.5, 0.0, 2.1, 7.8, 4.2])

# Metriken berechnen
mae = mean_absolute_error(target_true, target_pred)
mse = mean_squared_error(target_true, target_pred)
rmse = np.sqrt(mse)

print(f"MAE:  {mae:.4f}")
print(f"MSE:  {mse:.4f}")
print(f"RMSE: {rmse:.4f}")
```

**Ausgabe:**
```
MAE:  0.3800
MSE:  0.2120
RMSE: 0.4604
```

### Wann welche Metrik verwenden?

```mermaid
flowchart TD
    START["Welche Metrik<br/>verwenden?"]
    
    OUTLIER{"AusreiÃŸer<br/>vorhanden?"}
    INTERPRET{"Einfache<br/>Interpretation<br/>wichtig?"}
    PENALTY{"GroÃŸe Fehler<br/>stark bestrafen?"}
    
    MAE_CHOICE["âœ… MAE<br/>verwenden"]
    MSE_CHOICE["âœ… MSE/RMSE<br/>verwenden"]
    RMSE_CHOICE["âœ… RMSE<br/>verwenden"]
    
    START --> OUTLIER
    OUTLIER -->|Ja| MAE_CHOICE
    OUTLIER -->|Nein| PENALTY
    PENALTY -->|Ja| MSE_CHOICE
    PENALTY -->|Nein| INTERPRET
    INTERPRET -->|Ja| RMSE_CHOICE
    INTERPRET -->|Nein| MSE_CHOICE
    
    style MAE_CHOICE fill:#4CAF50,color:#fff
    style MSE_CHOICE fill:#FF9800,color:#fff
    style RMSE_CHOICE fill:#9C27B0,color:#fff
```

---

## Residual Plot (Residuenanalyse)

Ein Residualplot ist eine statistische Analyse, die Unterschiede zwischen beobachteten und modellvorhergesagten Werten visualisiert.

### Konzept

Residuen sind die Differenzen zwischen den tatsÃ¤chlichen und den vorhergesagten Werten. Ein Residualplot zeigt diese Modellfehler und hilft bei der Diagnose von Modellproblemen.

$$Residuum = y_i - \hat{y}_i$$

<img src="https://raw.githubusercontent.com/ralf-42/ML_Intro/main/07_image/residuals_plot.png" class="logo" width="650"/>

### Interpretation von Residual Plots

| Muster            | Bedeutung                       | Aktion                                     |
| ----------------- | ------------------------------- | ------------------------------------------ |
| **ZufÃ¤llig um 0** | Modell erfasst Zusammenhang gut | âœ… Modell ist geeignet                      |
| **Trichterform**  | HeteroskedastizitÃ¤t             | Transformation der Zielvariable            |
| **Kurve/Bogen**   | Nicht-linearer Zusammenhang     | Polynomiale Features hinzufÃ¼gen            |
| **Cluster**       | Subgruppen in Daten             | Separate Modelle oder zusÃ¤tzliche Features |

<img src="https://raw.githubusercontent.com/ralf-42/ML_Intro/main/07_image/residuenanalyse_linear_nichtlinear.png" class="logo" width="650"/>

### Visuelle Muster erkennen

```mermaid
flowchart LR
    subgraph Patterns["Residuen-Muster"]
        RANDOM["ğŸ² ZufÃ¤llig<br/>â”â”â”â”â”â”â”â”â”â”<br/>âœ… Ideal"]
        FUNNEL["ğŸ“ Trichter<br/>â—â”â”â”â”â”â”â”â–·<br/>âš ï¸ ungleiche Varianz"]
        CURVE["ã€°ï¸ Kurve<br/>âŒ’â”â”â”â”â”â”âŒ’<br/>âš ï¸ Nicht-linear"]
    end
    
    style RANDOM fill:#4CAF50,color:#fff
    style FUNNEL fill:#FF9800,color:#fff
    style CURVE fill:#f44336,color:#fff
```

### Implementation in Python

```python
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# Beispieldaten generieren
np.random.seed(42)
data = np.random.rand(100, 1) * 10
target = 2.5 * data.flatten() + np.random.randn(100) * 2

# Train-Test-Split
data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=42)

# Modell trainieren
model = LinearRegression()
model.fit(data_train, target_train)

# Vorhersagen
target_pred_train = model.predict(data_train)
target_pred_test = model.predict(data_test)

# Residuen berechnen
residuals_train = target_train - target_pred_train
residuals_test = target_test - target_pred_test

# Residual Plot erstellen
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Residuen vs. Vorhergesagte Werte
axes[0].scatter(target_pred_test, residuals_test, alpha=0.7, edgecolors='black')
axes[0].axhline(y=0, color='red', linestyle='--', linewidth=2)
axes[0].set_xlabel('Vorhergesagte Werte')
axes[0].set_ylabel('Residuen')
axes[0].set_title('Residual Plot')
axes[0].grid(True, alpha=0.3)

# Plot 2: Histogramm der Residuen
axes[1].hist(residuals_test, bins=15, edgecolor='black', alpha=0.7)
axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)
axes[1].set_xlabel('Residuen')
axes[1].set_ylabel('HÃ¤ufigkeit')
axes[1].set_title('Verteilung der Residuen')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### VollstÃ¤ndige Evaluation mit allen Metriken

```python
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

def evaluate_regression(target_true, target_pred, dataset_name=""):
    """
    VollstÃ¤ndige Evaluation eines Regressionsmodells.

    Parameters:
    -----------
    target_true : array-like
        TatsÃ¤chliche Werte
    target_pred : array-like
        Vorhergesagte Werte
    dataset_name : str
        Name des Datensatzes (z.B. 'Training' oder 'Test')

    Returns:
    --------
    dict : Dictionary mit allen Metriken
    """
    metrics = {
        'RÂ²': r2_score(target_true, target_pred),
        'MAE': mean_absolute_error(target_true, target_pred),
        'MSE': mean_squared_error(target_true, target_pred),
        'RMSE': np.sqrt(mean_squared_error(target_true, target_pred))
    }

    print(f"\n{'='*40}")
    print(f"Evaluation: {dataset_name}")
    print(f"{'='*40}")
    for metric, value in metrics.items():
        print(f"{metric:6s}: {value:.4f}")

    return metrics

# Anwendung
metrics_train = evaluate_regression(target_train, target_pred_train, "Training")
metrics_test = evaluate_regression(target_test, target_pred_test, "Test")
```

---

## Best Practices

### Checkliste fÃ¼r Regressions-Evaluation

- [ ] **RÂ² fÃ¼r Training und Test berechnen** â€“ GroÃŸer Unterschied deutet auf Overfitting hin
- [ ] **MAE und RMSE vergleichen** â€“ GroÃŸer Unterschied deutet auf AusreiÃŸer hin
- [ ] **Residual Plot analysieren** â€“ Auf Muster und ungleiche Varianz prÃ¼fen
- [ ] **Residuen auf Normalverteilung prÃ¼fen** â€“ Histogramm und Q-Q-Plot nutzen
- [ ] **Cross-Validation durchfÃ¼hren** â€“ StabilitÃ¤t der Metriken Ã¼ber Folds prÃ¼fen

### Typische Fehler vermeiden

| Fehler | Problem | LÃ¶sung |
|--------|---------|--------|
| Nur RÂ² betrachten | Kann irrefÃ¼hrend sein | Mehrere Metriken kombinieren |
| Train-Score als MaÃŸstab | Overfitting Ã¼bersehen | Test-Score priorisieren |
| Residuen ignorieren | Modellprobleme Ã¼bersehen | Immer Residual Plot erstellen |
| Skala ignorieren | MAE/RMSE nicht vergleichbar | Auf Einheit der Zielvariable achten |

---

## Zusammenfassung

```mermaid
flowchart TD
    subgraph Evaluation["ğŸ¯ Regressions-Evaluation"]
        R2["**RÂ²**<br/>ErklÃ¤rte Varianz<br/>0-1 (hÃ¶her = besser)"]
        MAE["**MAE**<br/>Mittlerer absoluter Fehler<br/>Robust gegen AusreiÃŸer"]
        RESIDUAL["**Residual Plot**<br/>Modelldiagnose<br/>Muster erkennen"]
    end
    
    subgraph Anwendung["ğŸ“‹ Anwendung"]
        VERGLEICH["Modellvergleich"]
        DIAGNOSE["Problemdiagnose"]
        OPTIMIERUNG["Modelloptimierung"]
    end
    
    R2 --> VERGLEICH
    MAE --> VERGLEICH
    RESIDUAL --> DIAGNOSE
    DIAGNOSE --> OPTIMIERUNG
    
    style R2 fill:#4CAF50,color:#fff
    style MAE fill:#2196F3,color:#fff
    style RESIDUAL fill:#9C27B0,color:#fff
```

| Metrik | StÃ¤rke | SchwÃ¤che |
|--------|--------|----------|
| **RÂ²** | Leicht interpretierbar, standardisiert | Kann bei nicht-linearen ZusammenhÃ¤ngen irrefÃ¼hren |
| **MAE** | Robust gegen AusreiÃŸer | Keine Bestrafung groÃŸer Fehler |
| **RMSE** | Bestraft groÃŸe Fehler, gleiche Einheit | Empfindlich gegen AusreiÃŸer |
| **Residual Plot** | Zeigt Modellprobleme visuell | Subjektive Interpretation |


---

**Version:** 1.0     
**Stand:** Januar 2026    
**Kurs:** Machine Learning. Verstehen. Anwenden. Gestalten.    